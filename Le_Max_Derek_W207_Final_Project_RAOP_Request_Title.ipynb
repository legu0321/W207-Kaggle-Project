{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Acts of Pizza (RAOP) Notes\n",
    "\n",
    "**Source**: Althoff, T., Danescu-Niculescu-Mizil, C., & Jurafsky, D. (2014). *How to Ask for a Favor: A Case Study on the Success of Altruistic Requests*. Association for the Advancement of Artificial\n",
    "Intelligence (www.aaai.org).\n",
    "\n",
    "- \"The community only publishes which users have given or received pizzas but not which requests were successful. \n",
    "In the case of successful users posting multiple times it is unclear which of the requests was actually successful. \n",
    "Therefore, we restrict our analysis to users with a single request for which we can be certain whether or not \n",
    "it was successful, leaving us with 5728 pizza requests. We split this dataset into development(70%) and test set (30%) \n",
    "such that both sets mirror the average success rate in our dataset of 24.6%. All features are developed on the \n",
    "development test only while the test set is used only once to evaluate the prediction accuracy of our proposed model on held-out data. For a small number of requests (379) we further observe the identity of the benefactor through a \n",
    "'thank you' post by the beneficiary after the successful request. This enables us to reason about the impact of \n",
    "user similarity on giving.\"\n",
    "\n",
    "\n",
    "- \"It is extremely difficult to disentangle the effects of all these factors in determining what makes people satisfy requests, and what makes them select some requests over others. . . In this paper, we develop a framework for controlling for each of these potential confounds while studying the role of two aspects that characterize compelling requests: **social factors** (who is asking and how the recipient is related to the donor and community) and **linguistic factors** (how they are asking and what linguistic devices accompany successful requests). With the notable exception of Mitra and Gilbert (2014), the effect of language on the success of requests has largely been ignored thus far.\"\n",
    "\n",
    "\n",
    "- \"[Their] goal is to understand what motivates people to give when they do not receive anything tangible in return. That is, [they] focus on the important special case of altruistic requests in which the giver receives no rewards.\" **DSC**: But how do you know people don't want something in return, especially if they are more likely to help requesters who have high status or are more similar to them?\n",
    "\n",
    "-----\n",
    "\n",
    "Temporal Factors\n",
    "- Specific months\n",
    "- Weekdays\n",
    "- **Days of the month (first half of the month)**\n",
    "- Hour of the day\n",
    "- **Community age of the request (earlier the better)**\n",
    "\n",
    "Textual Factors\n",
    "- Politeness (e.g., **gratitude**)\n",
    "- **Evidentiality** (2nd largest parameter estimate)\n",
    "- Reciprocity (respond to a positive action with another positive action, **pay it forward**)\n",
    "- Sentiment (e.g., **urgency**)\n",
    "- **Length**\n",
    "\n",
    "Social Factors\n",
    "- **Status**\n",
    "    - karma points (up-votes minus down-votes) that Reddit counts on link submissions and comments,\n",
    "    - user has posted on RAOP before and thus could be considered a member of the sub-community. \n",
    "    - **user account age based on the hypothesis that “younger” accounts might be less trusted**\n",
    "\n",
    "\n",
    "- Similarity: intersection size between the set of the giver and receiver, and the Jaccard similarity (intersection\n",
    "over union) of the two. NOT included in logistic regression model.\n",
    "\n",
    "Narratives (identified through topic modeling)\n",
    "- **Desire**\n",
    "- **Family**\n",
    "- **Job**\n",
    "- **Money**\n",
    "- Student\n",
    "\n",
    "-----\n",
    "\n",
    "Conclusion\n",
    "- Drawing from social psychology literature [they] extract high-level social features from text that operationalize the relation between recipient and donor and demonstrate that these extracted relations are predictive of success. \n",
    "- [They] show that [they] can detect key narratives automatically that have significant impact on the success of the request. \n",
    "- [They] further demonstrate that linguistic indications of gratitude, evidentiality, and reciprocity, as well as the high status of the asker, all increase the likelihood of success, while neither politeness nor positive sentiment seem to be associated with success in [the] setting.\n",
    "\n",
    "Limitations\n",
    "- A shortcoming of any case study is that findings might be specific to the scenario at hand. While [they] have shown that particular linguistic and social factors differentiate between successful and unsuccessful requests [they] cannot claim a causal relationship between the proposed factors and success that would guarantee success. \n",
    "- Furthermore, the set of success factors studied in this work is likely to be incomplete as well and excludes,\n",
    "for instance, group behavior dynamics. \n",
    "- Despite these limitations, [they] hope that this work and the data [they] make available will provide a basis for further research on success factors and helping behavior in other online communities.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import codecs\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import *\n",
    "from pandas import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(X) <class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "train_labels\n",
      "----------\n",
      "[u'requester_received_pizza']\n",
      "(3975, 1)\n",
      "\n",
      "train_data\n",
      "----------\n",
      "[u'giver_username_if_known', u'in_test_set', u'number_of_downvotes_of_request_at_retrieval', u'number_of_upvotes_of_request_at_retrieval', u'post_was_edited', u'request_id', u'request_number_of_comments_at_retrieval', u'request_text', u'request_text_edit_aware', u'request_title', u'requester_account_age_in_days_at_request', u'requester_account_age_in_days_at_retrieval', u'requester_days_since_first_post_on_raop_at_request', u'requester_days_since_first_post_on_raop_at_retrieval', u'requester_number_of_comments_at_request', u'requester_number_of_comments_at_retrieval', u'requester_number_of_comments_in_raop_at_request', u'requester_number_of_comments_in_raop_at_retrieval', u'requester_number_of_posts_at_request', u'requester_number_of_posts_at_retrieval', u'requester_number_of_posts_on_raop_at_request', u'requester_number_of_posts_on_raop_at_retrieval', u'requester_number_of_subreddits_at_request', u'requester_subreddits_at_request', u'requester_upvotes_minus_downvotes_at_request', u'requester_upvotes_minus_downvotes_at_retrieval', u'requester_upvotes_plus_downvotes_at_request', u'requester_upvotes_plus_downvotes_at_retrieval', u'requester_user_flair', u'requester_username', u'unix_timestamp_of_request', u'unix_timestamp_of_request_utc']\n",
      "(3975, 32)\n",
      "\n",
      "dev_labels\n",
      "----------\n",
      "[u'requester_received_pizza']\n",
      "(1696, 1)\n",
      "\n",
      "dev_data\n",
      "----------\n",
      "[u'giver_username_if_known', u'in_test_set', u'number_of_downvotes_of_request_at_retrieval', u'number_of_upvotes_of_request_at_retrieval', u'post_was_edited', u'request_id', u'request_number_of_comments_at_retrieval', u'request_text', u'request_text_edit_aware', u'request_title', u'requester_account_age_in_days_at_request', u'requester_account_age_in_days_at_retrieval', u'requester_days_since_first_post_on_raop_at_request', u'requester_days_since_first_post_on_raop_at_retrieval', u'requester_number_of_comments_at_request', u'requester_number_of_comments_at_retrieval', u'requester_number_of_comments_in_raop_at_request', u'requester_number_of_comments_in_raop_at_retrieval', u'requester_number_of_posts_at_request', u'requester_number_of_posts_at_retrieval', u'requester_number_of_posts_on_raop_at_request', u'requester_number_of_posts_on_raop_at_retrieval', u'requester_number_of_subreddits_at_request', u'requester_subreddits_at_request', u'requester_upvotes_minus_downvotes_at_request', u'requester_upvotes_minus_downvotes_at_retrieval', u'requester_upvotes_plus_downvotes_at_request', u'requester_upvotes_plus_downvotes_at_retrieval', u'requester_user_flair', u'requester_username', u'unix_timestamp_of_request', u'unix_timestamp_of_request_utc']\n",
      "(1696, 32)\n",
      "\n",
      "train labels\n",
      "----------\n",
      "requester_received_pizza    0.241006\n",
      "dtype: float64\n",
      "\n",
      "dev labels\n",
      "----------\n",
      "requester_received_pizza    0.258844\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_json.html\n",
    "# Convert a JSON string to pandas object\n",
    "\n",
    "X = pd.read_json('./pizza_request_dataset.json')\n",
    "print \"type(X)\", type(X)\n",
    "print\n",
    "#print X.head()\n",
    "#print X.describe()\n",
    "#print\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# randomly assign 70% to train_data, and 30% to dev_data\n",
    "msk = np.random.rand(len(X)) <= 0.7\n",
    "train_data = X[msk]\n",
    "dev_data = X[~msk]\n",
    "\n",
    "# create output dataframe Y of train_labels\n",
    "train_labels = train_data[[\"requester_received_pizza\"]]\n",
    "\n",
    "# delete train_labels from input dataframe of train_data\n",
    "del train_data[\"requester_received_pizza\"]\n",
    "\n",
    "# create output dataframe of dev_labels\n",
    "dev_labels = dev_data[[\"requester_received_pizza\"]]\n",
    "#Y.describe()\n",
    "\n",
    "# delete dev_labels from input dataframe of dev_data\n",
    "del dev_data[\"requester_received_pizza\"]\n",
    "\n",
    "# print labels, shapes, and feature names\n",
    "print \"train_labels\" \n",
    "print \"----------\"\n",
    "print list(train_labels)\n",
    "print train_labels.shape\n",
    "print\n",
    "print \"train_data\" \n",
    "print \"----------\"\n",
    "print list(train_data)\n",
    "print train_data.shape\n",
    "print\n",
    "\n",
    "print \"dev_labels\" \n",
    "print \"----------\"\n",
    "print list(dev_labels)\n",
    "print dev_labels.shape\n",
    "print\n",
    "print \"dev_data\"\n",
    "print \"----------\"\n",
    "print list(dev_data)\n",
    "print dev_data.shape\n",
    "print\n",
    "\n",
    "# print percent of train_data and dev_data whose posts led to receipt of pizza\n",
    "print \"train labels\"\n",
    "print \"----------\"\n",
    "print np.mean(train_labels)\n",
    "print\n",
    "print \"dev labels\"\n",
    "print \"----------\"\n",
    "print np.mean(dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0\n",
      "0  A\n",
      "1  B\n",
      "2  C\n",
      "numpy.ndarray:\n",
      "<type 'numpy.ndarray'>\n",
      "(3,)\n",
      "['A' 'B' 'C']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test function before use\n",
    "\n",
    "data = ['A','B','C']\n",
    "df = pd.DataFrame(data=data)\n",
    "print df\n",
    "\n",
    "df.shape\n",
    "\n",
    "def to_np(d):\n",
    "    \n",
    "    # convert to numpy array\n",
    "    print \"numpy.ndarray:\"\n",
    "    d = array(d)\n",
    "    # http://stackoverflow.com/questions/13730468/from-2d-to-1d-arrays\n",
    "    d = d.flatten()\n",
    "    print type(d)\n",
    "    print d.shape\n",
    "    print d[:3]\n",
    "    return d\n",
    "\n",
    "df = to_np(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(train_text) <class 'pandas.core.series.Series'>\n",
      "type(train_labels) <class 'pandas.core.frame.DataFrame'>\n",
      "type(dev_text) <class 'pandas.core.series.Series'>\n",
      "type(dev_labels) <class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "pandas dataframe:\n",
      "0     [Request] Ontario, Canada - On my 3rd of 5 day...\n",
      "2           [Request] Pizza for a broke college student\n",
      "3     [Request] Unemployed and Sick of Rice (Suffolk...\n",
      "4     [Request] Ohio USA, broke student musician in ...\n",
      "5     [Request] [Manteca, CA] 17 days sober and kind...\n",
      "6     [request] Camden, SC USA - Broke until Thursda...\n",
      "9      [Request] College Student would love a pizza... \n",
      "11                    [Request] Will Perform for Pizza.\n",
      "12            [Request] Seattle Nearly Broke and Hungry\n",
      "14    [Request]Doing it rough. Paying off debt from ...\n",
      "Name: request_title, dtype: object\n",
      "\n",
      "numpy.ndarray:\n",
      "<type 'numpy.ndarray'>\n",
      "(3975,)\n",
      "[ u\"[Request] Ontario, Canada - On my 3rd of 5 days without food, and it's getting unbearable. Can anyone help?\"\n",
      " u'[Request] Pizza for a broke college student'\n",
      " u'[Request] Unemployed and Sick of Rice (Suffolk County, NY)']\n",
      "\n",
      "numpy.ndarray:\n",
      "<type 'numpy.ndarray'>\n",
      "(3975,)\n",
      "[ True  True  True]\n",
      "\n",
      "numpy.ndarray:\n",
      "<type 'numpy.ndarray'>\n",
      "(1696,)\n",
      "[u'[REQUEST] Southern Arizona, Tucson Hungry Family'\n",
      " u'[request] college student, just started first job. Thought payday was Friday, not till the first. Ran out of food yesterday.'\n",
      " u'[request] Had to put my dog down today. broke could really use a pizza. Melbourne, Australia.']\n",
      "\n",
      "numpy.ndarray:\n",
      "<type 'numpy.ndarray'>\n",
      "(1696,)\n",
      "[ True  True  True]\n",
      "\n",
      "train_labels.shape: (3975,)\n",
      "dev_labels.shape: (1696,)\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "# transform X to numpy array, and Y to 1-D numpy array\n",
    "# view actual text and labels\n",
    "\n",
    "train_text = train_data[\"request_title\"]\n",
    "dev_text = dev_data[\"request_title\"]\n",
    "\n",
    "print \"type(train_text)\", type(train_text)\n",
    "print \"type(train_labels)\", type(train_labels)\n",
    "print \"type(dev_text)\", type(dev_text)\n",
    "print \"type(dev_labels)\", type(dev_labels)\n",
    "print\n",
    "\n",
    "#from numpy import *\n",
    "\n",
    "# view as pandas dataframe\n",
    "print \"pandas dataframe:\"\n",
    "print train_text[:10]\n",
    "print\n",
    "\n",
    "# convert to numpy (np) array\n",
    "\n",
    "def to_np(d):\n",
    "\n",
    "    print \"numpy.ndarray:\"\n",
    "    d = array(d)\n",
    "    # http://stackoverflow.com/questions/13730468/from-2d-to-1d-arrays\n",
    "    d = d.flatten()\n",
    "    print type(d)\n",
    "    print d.shape\n",
    "    print d[:3]\n",
    "    print\n",
    "    return d\n",
    "\n",
    "train_text = to_np(train_text)\n",
    "train_labels = to_np(train_labels)\n",
    "dev_text = to_np(dev_text)\n",
    "dev_labels = to_np(dev_labels)\n",
    "\n",
    "# convert to list\n",
    "\n",
    "def to_list(d):\n",
    "\n",
    "\n",
    "    print \"list:\"\n",
    "    d = list(d)\n",
    "    print type(d)\n",
    "    print d[:3]\n",
    "    print \n",
    "    return d\n",
    "\n",
    "#train_text = to_list(train_text)\n",
    "#dev_text = to_list(dev_text)\n",
    "\n",
    "print \"train_labels.shape:\", train_labels.shape\n",
    "print \"dev_labels.shape:\", dev_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vectors.shape: (3975, 4244)\n",
      "dev_vectors.shape: (1696, 4244)\n",
      "\n",
      "------------------------------\n",
      "K Nearest Neighbors (K-NN)\n",
      "------------------------------\n",
      "K-NN: f1_score = 0.2813, k = 1\n",
      "K-NN: f1_score = 0.1678, k = 5\n",
      "K-NN: f1_score = 0.0469, k = 15\n",
      "K-NN: f1_score = 0.0352, k = 16\n",
      "K-NN: f1_score = 0.039, k = 17\n",
      "K-NN: f1_score = 0.0223, k = 18\n",
      "K-NN: f1_score = 0.0523, k = 19\n",
      "K-NN: f1_score = 0.0224, k = 20\n",
      "K-NN: f1_score = 0.0, k = 28\n",
      "K-NN: f1_score = 0.0, k = 29\n",
      "K-NN: f1_score = 0.0, k = 30\n",
      "K-NN: f1_score = 0.0, k = 31\n",
      "K-NN: f1_score = 0.0, k = 32\n",
      "K-NN: f1_score = 0.0, k = 150\n",
      "K-NN: f1_score = 0.0, k = 300\n",
      "\n",
      "K-NN: optimal k = 1\n",
      "\n",
      "-----------------------------\n",
      "Bernoulli Naive Bayes (BNB)\n",
      "-----------------------------\n",
      "BNB: f1_score = 0.1173, alpha = 0.0\n",
      "BNB: f1_score = 0.2526, alpha = 1e-05\n",
      "BNB: f1_score = 0.2526, alpha = 0.0001\n",
      "BNB: f1_score = 0.2526, alpha = 0.001\n",
      "BNB: f1_score = 0.2526, alpha = 0.01\n",
      "BNB: f1_score = 0.1845, alpha = 0.094\n",
      "BNB: f1_score = 0.1845, alpha = 0.095\n",
      "BNB: f1_score = 0.1845, alpha = 0.096\n",
      "BNB: f1_score = 0.1845, alpha = 0.1\n",
      "BNB: f1_score = 0.1851, alpha = 0.105\n",
      "BNB: f1_score = 0.1764, alpha = 0.2\n",
      "BNB: f1_score = 0.1725, alpha = 0.3\n",
      "BNB: f1_score = 0.1157, alpha = 0.4\n",
      "BNB: f1_score = 0.0714, alpha = 0.5\n",
      "BNB: f1_score = 0.065, alpha = 0.6\n",
      "BNB: f1_score = 0.039, alpha = 0.7\n",
      "BNB: f1_score = 0.0, alpha = 1.0\n",
      "BNB: f1_score = 0.0, alpha = 10.0\n",
      "\n",
      "Bernoulli Naive Bayes: optimal alpha = 1e-05\n",
      "\n",
      "------------------------\n",
      "Logistic Regression (LR)\n",
      "------------------------\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0, C = 0.01\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 0.11\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0, C = 0.1\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 7.02\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0, C = 0.2\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 23.87\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0, C = 0.3\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 47.51\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0, C = 0.4\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 76.27\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0, C = 0.5\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 109.19\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0, C = 0.54\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 123.34\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0, C = 0.55\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 126.95\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0, C = 0.56\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 130.6\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0, C = 0.57\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 134.28\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0, C = 0.58\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 137.98\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0, C = 0.59\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 141.72\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0, C = 0.6\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 145.48\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0045, C = 0.7\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 184.64\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0045, C = 0.8\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 226.26\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.009, C = 0.9\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 270.02\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0221, C = 1.0\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 315.65\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0221, C = 1.1\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 362.96\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.2062, C = 10\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 5761.12\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.2148, C = 12\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 6945.66\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.24, C = 20\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 11379.31\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.2557, C = 30\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 16366.47\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.255, C = 40\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 20886.26\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.2581, C = 50\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 25057.84\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.2733, C = 100\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 42598.87\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.2773, C = 1000\n",
      "-------------------------------\n",
      "Label = 1, sum of squared weights = 183919.8\n",
      "\n",
      "Logistic Regression: optimal C = 1000\n",
      "\n",
      "max accuracy = 74.1155660377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:51: DeprecationWarning: Passing additional arguments to the metric function as **kwargs is deprecated and will no longer be supported in 0.18. Use metric_params instead.\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "# http://stackoverflow.com/questions/209840/map-two-lists-into-a-dictionary-in-python\n",
    "# http://stackoverflow.com/questions/268272/getting-key-with-maximum-value-in-dictionary\n",
    "\n",
    "# Notes\n",
    "# Classifier precision--when a positive value is predicted, proportion of time the prediction is correct--equals (TP) / (TP + FP)\n",
    "# Classifier recall--when the actual value is positive, the proportion of time the prediction is correct--equals (TP) / (TP + FN)\n",
    "\n",
    "def explore_models():\n",
    "### STUDENT START ###\n",
    "\n",
    "    # create empty vector\n",
    "    accuracies = []\n",
    "\n",
    "    # Source: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "    # The F1 score can be interpreted as a weighted average of the precision and recall, \n",
    "    # where an F1 score reaches its best value at 1 and worst score at 0. \n",
    "    # The relative contribution of precision and recall to the F1 score are equal. \n",
    "    # The formula for the F1 score is: F1 = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(min_df=1, stop_words='english')\n",
    "    #vectorizer = CountVectorizer(min_df=1, stop_words='english')\n",
    "    train_vectors = vectorizer.fit_transform(train_text)\n",
    "    print \"train_vectors.shape:\", train_vectors.shape\n",
    "    \n",
    "    dev_vectors = vectorizer.transform(dev_text)\n",
    "    print \"dev_vectors.shape:\", dev_vectors.shape\n",
    "    print\n",
    "    \n",
    "    #------------------------\n",
    "    # K Nearest Neighbors\n",
    "    #------------------------\n",
    "    \n",
    "    print \"------------------------------\"\n",
    "    print \"K Nearest Neighbors (K-NN)\"\n",
    "    print \"------------------------------\"\n",
    "    \n",
    "    # Euclidean distance, when you go to 10 to 20+ dimensions, too many examples can be close to each other\n",
    "    # With K-NN on text, Cosine or Manhattan distance might be better. Cosine distance measures the angle between examples,\n",
    "    # more robust for high-dimensional problems. \n",
    "    # Dot product measures length of vectors AND angle between these vectors. \n",
    "    # With Cosine distance, you can get a value 0 to 1.\n",
    "    \n",
    "    # create two vectors\n",
    "    # ks refers to a vector of k nearest neighbor values\n",
    "    \n",
    "    ks = [1, 5, 15, 16, 17, 18, 19, 20, 28, 29, 30, 31, 32, 150, 300]\n",
    "    f1_scores = []\n",
    "    \n",
    "    for k in ks:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, distance='cosine', algorithm='brute')\n",
    "        knn.fit(train_vectors, train_labels)\n",
    "        pred_1 = knn.predict(dev_vectors)\n",
    "        \n",
    "        # http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "        # f1_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)[source]¶\n",
    "            # y_true = Ground truth (correct) target values \n",
    "            # y_pred = Estimated targets as returned by a classifier.\n",
    "            # average = required for multiclass/multilabel targets.\n",
    "                # 'weighted': Calculate metrics for each label, and find their average, weighted by \n",
    "                # the number of true instances for each label. This alters ‘macro’ to account for label imbalance; \n",
    "                # it can result in an F-score that is not between precision and recall.\n",
    "            \n",
    "        print \"K-NN: f1_score = %s, k = %s\" % (round(metrics.f1_score(dev_labels, pred_1, average='binary'),4), k)\n",
    "\n",
    "        # append f1_scores to vector\n",
    "        f1_scores.append(metrics.f1_score(dev_labels, pred_1))\n",
    "    \n",
    "    print\n",
    "    \n",
    "    # map two vectors into a dictionary\n",
    "    results_knn = dict(zip(ks, f1_scores))\n",
    "    #print results_knn\n",
    "    \n",
    "    # print the key with the max fl_score\n",
    "    print \"K-NN: optimal k =\", max(results_knn.iteritems(), key=operator.itemgetter(1))[0]\n",
    "    print\n",
    "\n",
    "    #------------------------\n",
    "    # Bernoulli Naive Bayes\n",
    "    #------------------------\n",
    "    \n",
    "    print \"-----------------------------\"\n",
    "    print \"Bernoulli Naive Bayes (BNB)\"\n",
    "    print \"-----------------------------\"\n",
    "    \n",
    "    # create two vectors\n",
    "    \n",
    "    alphas = [0.0, 0.00001, 0.0001, 0.001, 0.01, 0.094, 0.095, 0.096, 0.1, 0.105, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 1.0, 10.0]\n",
    "    f1_scores = []\n",
    "    \n",
    "    for a in alphas:\n",
    "        bnb = BernoulliNB(alpha=a,binarize=0.5)\n",
    "        bnb.fit(train_vectors, train_labels)\n",
    "        pred_2 = bnb.predict(dev_vectors)\n",
    "        print \"BNB: f1_score = %s, alpha = %s\" % (round(metrics.f1_score(dev_labels, pred_2, average='binary'), 4), a)\n",
    "        \n",
    "        # append f1_scores to vector\n",
    "        f1_scores.append(metrics.f1_score(dev_labels, pred_2))\n",
    "        \n",
    "    print\n",
    "    \n",
    "    # map two vectors into a dictionary\n",
    "    results_bnb = dict(zip(alphas, f1_scores))\n",
    "    #print results_mnb\n",
    "    \n",
    "    # print the key with the max fl_score\n",
    "    print \"Bernoulli Naive Bayes: optimal alpha =\", max(results_bnb.iteritems(), key=operator.itemgetter(1))[0]\n",
    "    print\n",
    "    \n",
    "    #------------------------\n",
    "    # Logistic Regression\n",
    "    #------------------------\n",
    "    \n",
    "    print \"------------------------\"\n",
    "    print \"Logistic Regression (LR)\"\n",
    "    print \"------------------------\"\n",
    "    print\n",
    "    \n",
    "    # create two vectors\n",
    "    # cs refers to the vector of C (inverse of regularization strength) values\n",
    "    \n",
    "    cs = [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, \\\n",
    "          10, 12, 20, 30, 40, 50, 100, 1000]\n",
    "    f1_scores = []\n",
    "    \n",
    "    for c in cs:\n",
    "        \n",
    "        # logistic regression fits a line like linear regression, but instead of predicting any number, \n",
    "        # it predicts a number between 0 and 1 (sigmoid function).\n",
    "        \n",
    "        # http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "        # C (inverse of regularization strength) controls how much the weights influence the loss, and\n",
    "        # penalizes the sum of squared weights if very different weights exist between different tokens.\n",
    "  \n",
    "        # use l2 regularization, per instructions\n",
    "        lr = LogisticRegression(penalty='l2',C=c)\n",
    "        lr.fit(train_vectors, train_labels)\n",
    "        pred_3 = lr.predict(dev_vectors)\n",
    "        \n",
    "        print \"-------------------------------\"\n",
    "        print \"LR: f1_score = %s, C = %s\" % (round(metrics.f1_score(dev_labels, pred_3, average='binary'),4), c)\n",
    "        print \"-------------------------------\"\n",
    "        \n",
    "        # append f1_scores to vector\n",
    "        f1_scores.append(metrics.f1_score(dev_labels, pred_3, average='binary'))\n",
    "        \n",
    "        accuracies.append((lr.score(dev_vectors, dev_labels))*100) \n",
    "\n",
    "        #print lr.coef_.shape\n",
    "        \n",
    "        # first define function that squares a given value, for later use in the 'for loop' below\n",
    "        fun_sq_wts = lambda x: x**2\n",
    "        \n",
    "        # use map function, likely faster (because written in C) than list comprehension.\n",
    "        # map function itself applies a function, specifically the first argument on the second argument.\n",
    "        # from coef_, take raw weights (coefficient of the features in the decision function), \n",
    "        # and sum the squares of these weights.\n",
    "\n",
    "        # note: averege=weight vs. average=default should be about same score if similar number of examples across classes\n",
    "        sq_wts = map(fun_sq_wts, lr.coef_[0])\n",
    "        sum_sq_wts = round(sum(sq_wts),2)\n",
    "        print \"Label = 1, sum of squared weights = %s\" % (sum_sq_wts)\n",
    "\n",
    "        print\n",
    "        \n",
    "    # map two vectors into a dictionary\n",
    "    results_lr = dict(zip(cs, f1_scores))\n",
    "    #print results_lr\n",
    "    \n",
    "    # print the key with the max fl_score\n",
    "    print \"Logistic Regression: optimal C =\", max(results_lr.iteritems(), key=operator.itemgetter(1))[0]\n",
    "    print\n",
    "    print \"max accuracy =\", max(accuracies)\n",
    "        \n",
    "### STUDENT END ###\n",
    "\n",
    "explore_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------\n",
      "unigram\n",
      "----------\n",
      "\n",
      "train_vectors.shape: (3975, 4244)\n",
      "\n",
      "lr.coef_:\n",
      "[[ 1.22583965 -0.33351288 -1.00257004 ..., -1.78196946 -0.3782465\n",
      "  -1.25021217]]\n",
      "\n",
      "top 20:\n",
      "[283, 1415, 3020, 733, 3159, 2339, 2314, 3563, 1414, 2564, 4070, 746, 1681, 2207, 3384, 1049, 2015, 2239, 762, 2610]\n",
      "\n",
      "        Feature      word\n",
      "0           ask  5.258964\n",
      "1          flat  4.578794\n",
      "2         ranch  4.509129\n",
      "3     christmas  4.420202\n",
      "4        return  4.378469\n",
      "5         metro  4.373254\n",
      "6        medium  4.250303\n",
      "7    starvation  4.231411\n",
      "8     flagstaff  4.172278\n",
      "9     northwest  4.113056\n",
      "10         want -4.080508\n",
      "11  clarksville  4.018747\n",
      "12         hang  3.997245\n",
      "13          lot  3.989868\n",
      "14     shoulder  3.983606\n",
      "15         didn  3.938906\n",
      "16     kentucky  3.903408\n",
      "17          mac  3.868209\n",
      "18        cloud  3.851382\n",
      "19   officially  3.839542\n",
      "\n",
      "----------\n",
      "bigram\n",
      "----------\n",
      "\n",
      "train_vectors.shape: (3975, 16870)\n",
      "\n",
      "lr.coef_:\n",
      "[[ 1.00114232 -0.18944685 -0.32656169 ..., -0.29237936 -0.24410407\n",
      "  -0.44448033]]\n",
      "\n",
      "top 20:\n",
      "[10258, 12410, 10935, 10346, 2386, 11890, 10572, 10203, 7688, 6863, 15692, 9184, 10238, 10297, 10705, 5748, 802, 15798, 16617, 7099]\n",
      "\n",
      "              Feature      word\n",
      "0            pizza ca  3.904432\n",
      "1      request reddit  3.850235\n",
      "2     pregnant hungry  3.767471\n",
      "3          pizza feed  3.697681\n",
      "4        college girl  3.628610\n",
      "5      request father  3.534112\n",
      "6          pizza read  3.489110\n",
      "7   pizza anniversary  3.463711\n",
      "8      little brother  3.462970\n",
      "9          job pantry  3.392770\n",
      "10           usa love  3.367045\n",
      "11           new site  3.342416\n",
      "12       pizza boerne  3.339976\n",
      "13     pizza daughter  3.298519\n",
      "14         pizza work  3.294175\n",
      "15           help dad  3.201927\n",
      "16     awesome return  3.163616\n",
      "17          use smile  3.121611\n",
      "18        work really  3.093654\n",
      "19       just surgery  3.092340\n"
     ]
    }
   ],
   "source": [
    "from pandas import *\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Feature Selection Notes:\n",
    "'''\n",
    "http://scikit-learn.org/stable/datasets/twenty_newsgroups.html\n",
    "http://scikit-learn.org/stable/modules/feature_selection.html\n",
    "http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html#example-text-document-classification-20newsgroups-py\n",
    "\n",
    "These objects take as input a scoring function that returns univariate p-values:\n",
    "-For regression: f_regression\n",
    "-For classification: chi2 or f_classif\n",
    "\n",
    "Feature selection with sparse data:\n",
    "-If you use sparse data (i.e. data represented as sparse matrices), \n",
    "only chi2 will deal with the data without making it dense.\n",
    "-Warning: Beware not to use a regression scoring function with a classification problem, \n",
    "you will get useless results.\n",
    "\n",
    "With SVMs and logistic-regression, the parameter C controls the sparsity: \n",
    "the smaller C the less features selected. \n",
    "'''\n",
    "\n",
    "def top20(type):\n",
    "### STUDENT START ###\n",
    "\n",
    "    if type == \"unigram\":\n",
    "        \n",
    "        # use stop_words='english' to remove less meaningful words. \n",
    "        # only applies if default analyzer='word'.\n",
    "        vectorizer = TfidfVectorizer(min_df=1, stop_words='english')\n",
    "        #vectorizer = CountVectorizer(min_df=1, stop_words='english')\n",
    "        train_vectors = vectorizer.fit_transform(train_text)\n",
    "        print\n",
    "        print \"----------\"\n",
    "        print \"unigram\"\n",
    "        print \"----------\"\n",
    "        print\n",
    "        print \"train_vectors.shape:\", train_vectors.shape\n",
    "        print\n",
    "        \n",
    "    elif type == \"bigram\":\n",
    "        \n",
    "        # use stop_words='english' to remove less meaningful words from the resulting tokens. \n",
    "        # only applies if default analyzer='word'.\n",
    "        # set bigrams to be 2 words only\n",
    "        vectorizer = TfidfVectorizer(min_df=1, stop_words='english', ngram_range=(2, 2))\n",
    "        #vectorizer = CountVectorizer(min_df=1, stop_words='english', ngram_range=(2, 2))\n",
    "        train_vectors = vectorizer.fit_transform(train_text)\n",
    "        print\n",
    "        print \"----------\"\n",
    "        print \"bigram\"\n",
    "        print \"----------\"\n",
    "        print\n",
    "        print \"train_vectors.shape:\", train_vectors.shape\n",
    "        print\n",
    "      \n",
    "    # use C=12\n",
    "    for c in [12]:\n",
    "        \n",
    "        # in the multiclass case, the training algorithm uses the one-vs-rest (OvR) scheme if the default ‘multi_class’ option is set to ‘ovr’ \n",
    "        lr = LogisticRegression(penalty='l2',C=c)\n",
    "        #print lr\n",
    "        \n",
    "        # fit the model and generate coef_\n",
    "        lr.fit(train_vectors, train_labels)\n",
    "         \n",
    "        # interested in magnitude of the weights (coefficients), so take absolute value.\n",
    "        # sort absolute values in descending order.\n",
    "        # important to know if negative or positive weight, so still output the positive/negative sign.\n",
    "        # after fitting logistic regression for class vs. all other classes, negative weight of a token \n",
    "        # indicates a class other than class of interest.\n",
    "        # (visual example of negative and positive on a sigmoid function helps) \n",
    "        \n",
    "        print \"lr.coef_:\"\n",
    "        print lr.coef_\n",
    "        print\n",
    "        \n",
    "        # for each label, store the column indices of the top 5 weights \n",
    "        top20 = sorted(range(len(lr.coef_[0])), key=lambda i: abs(lr.coef_[0][i]), reverse=True)[:20]\n",
    "       \n",
    "        col_1 = []\n",
    "        \n",
    "        # for each label, access and store weights via column indices\n",
    "        for index in (top20):\n",
    "\n",
    "            col_1.append(lr.coef_[0][index])\n",
    "           \n",
    "        print \"top 20:\" \n",
    "        print top20\n",
    "        print\n",
    "        \n",
    "        # store feature names, after converting to an array\n",
    "        feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "       \n",
    "        # create a Pandas dataframe with 20 rows and 4 columns, plus descriptive headers\n",
    "        df = DataFrame({'Feature': feature_names[top20], 'word': col_1})\n",
    "        print df    \n",
    "\n",
    "#-----\n",
    "         \n",
    "### STUDENT END ###\n",
    "top20(\"unigram\")\n",
    "top20(\"bigram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "C =  0.01\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.0\n",
      "LR L2 regularization: f1_score = 0.0\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 0\n",
      "LR L2 regularization: number of non-zero weights = 4244\n",
      "\n",
      "LR L1 regularization: accuracy = 74.12%\n",
      "LR L2 regularization: accuracy = 74.12%\n",
      "\n",
      "-----------------\n",
      "C =  0.03\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.0\n",
      "LR L2 regularization: f1_score = 0.0\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 0\n",
      "LR L2 regularization: number of non-zero weights = 4244\n",
      "\n",
      "LR L1 regularization: accuracy = 74.12%\n",
      "LR L2 regularization: accuracy = 74.12%\n",
      "\n",
      "-----------------\n",
      "C =  0.05\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.0\n",
      "LR L2 regularization: f1_score = 0.0\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 0\n",
      "LR L2 regularization: number of non-zero weights = 4244\n",
      "\n",
      "LR L1 regularization: accuracy = 74.12%\n",
      "LR L2 regularization: accuracy = 74.12%\n",
      "\n",
      "-----------------\n",
      "C =  0.07\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.0\n",
      "LR L2 regularization: f1_score = 0.0\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 0\n",
      "LR L2 regularization: number of non-zero weights = 4244\n",
      "\n",
      "LR L1 regularization: accuracy = 74.12%\n",
      "LR L2 regularization: accuracy = 74.12%\n",
      "\n",
      "-----------------\n",
      "C =  0.1\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.0\n",
      "LR L2 regularization: f1_score = 0.0\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 0\n",
      "LR L2 regularization: number of non-zero weights = 4244\n",
      "\n",
      "LR L1 regularization: accuracy = 74.12%\n",
      "LR L2 regularization: accuracy = 74.12%\n",
      "\n",
      "-----------------\n",
      "C =  0.3\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.0\n",
      "LR L2 regularization: f1_score = 0.0\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 6\n",
      "LR L2 regularization: number of non-zero weights = 4244\n",
      "\n",
      "LR L1 regularization: accuracy = 74.12%\n",
      "LR L2 regularization: accuracy = 74.12%\n",
      "\n",
      "***Re-trained model w/ L1 non-zero features***\n",
      "LR L2 regularization: f1_score = 0.0\n",
      "LR L2 regularization: number of non-zero weights: 6\n",
      "LR L2 regularization: accuracy = 74.12%\n",
      "\n",
      "LR L2 regularization: vocab size: 6\n",
      "\n",
      "-----------------\n",
      "C =  0.5\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.0\n",
      "LR L2 regularization: f1_score = 0.0\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 31\n",
      "LR L2 regularization: number of non-zero weights = 4244\n",
      "\n",
      "LR L1 regularization: accuracy = 74.06%\n",
      "LR L2 regularization: accuracy = 74.06%\n",
      "\n",
      "***Re-trained model w/ L1 non-zero features***\n",
      "LR L2 regularization: f1_score = 0.0\n",
      "LR L2 regularization: number of non-zero weights: 31\n",
      "LR L2 regularization: accuracy = 74.12%\n",
      "\n",
      "LR L2 regularization: vocab size: 31\n",
      "\n",
      "-----------------\n",
      "C =  0.57\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.0045\n",
      "LR L2 regularization: f1_score = 0.0\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 39\n",
      "LR L2 regularization: number of non-zero weights = 4244\n",
      "\n",
      "LR L1 regularization: accuracy = 74.06%\n",
      "LR L2 regularization: accuracy = 74.06%\n",
      "\n",
      "***Re-trained model w/ L1 non-zero features***\n",
      "LR L2 regularization: f1_score = 0.0\n",
      "LR L2 regularization: number of non-zero weights: 39\n",
      "LR L2 regularization: accuracy = 74.12%\n",
      "\n",
      "LR L2 regularization: vocab size: 39\n",
      "\n",
      "-----------------\n",
      "C =  0.7\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.0135\n",
      "LR L2 regularization: f1_score = 0.0045\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 59\n",
      "LR L2 regularization: number of non-zero weights = 4244\n",
      "\n",
      "LR L1 regularization: accuracy = 74.12%\n",
      "LR L2 regularization: accuracy = 74.06%\n",
      "\n",
      "***Re-trained model w/ L1 non-zero features***\n",
      "LR L2 regularization: f1_score = 0.0\n",
      "LR L2 regularization: number of non-zero weights: 59\n",
      "LR L2 regularization: accuracy = 74.12%\n",
      "\n",
      "LR L2 regularization: vocab size: 59\n",
      "\n",
      "-----------------\n",
      "C =  1.0\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.0349\n",
      "LR L2 regularization: f1_score = 0.0177\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 136\n",
      "LR L2 regularization: number of non-zero weights = 4244\n",
      "\n",
      "LR L1 regularization: accuracy = 73.88%\n",
      "LR L2 regularization: accuracy = 73.88%\n",
      "\n",
      "***Re-trained model w/ L1 non-zero features***\n",
      "LR L2 regularization: f1_score = 0.0\n",
      "LR L2 regularization: number of non-zero weights: 136\n",
      "LR L2 regularization: accuracy = 74.12%\n",
      "\n",
      "LR L2 regularization: vocab size: 136\n",
      "\n",
      "-----------------\n",
      "C =  10.0\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.259\n",
      "LR L2 regularization: f1_score = 0.2097\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 1656\n",
      "LR L2 regularization: number of non-zero weights = 4244\n",
      "\n",
      "LR L1 regularization: accuracy = 68.28%\n",
      "LR L2 regularization: accuracy = 70.22%\n",
      "\n",
      "***Re-trained model w/ L1 non-zero features***\n",
      "LR L2 regularization: f1_score = 0.0175\n",
      "LR L2 regularization: number of non-zero weights: 1656\n",
      "LR L2 regularization: accuracy = 73.58%\n",
      "\n",
      "LR L2 regularization: vocab size: 1656\n",
      "\n",
      "-----------------\n",
      "C =  12.0\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.2663\n",
      "LR L2 regularization: f1_score = 0.2144\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 1750\n",
      "LR L2 regularization: number of non-zero weights = 4244\n",
      "\n",
      "LR L1 regularization: accuracy = 67.51%\n",
      "LR L2 regularization: accuracy = 69.75%\n",
      "\n",
      "***Re-trained model w/ L1 non-zero features***\n",
      "LR L2 regularization: f1_score = 0.0218\n",
      "LR L2 regularization: number of non-zero weights: 1750\n",
      "LR L2 regularization: accuracy = 73.58%\n",
      "\n",
      "LR L2 regularization: vocab size: 1750\n",
      "\n",
      "-----------------\n",
      "C =  30.0\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.2885\n",
      "LR L2 regularization: f1_score = 0.2493\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 2085\n",
      "LR L2 regularization: number of non-zero weights = 4244\n",
      "\n",
      "LR L1 regularization: accuracy = 65.39%\n",
      "LR L2 regularization: accuracy = 67.33%\n",
      "\n",
      "***Re-trained model w/ L1 non-zero features***\n",
      "LR L2 regularization: f1_score = 0.0262\n",
      "LR L2 regularization: number of non-zero weights: 2085\n",
      "LR L2 regularization: accuracy = 73.70%\n",
      "\n",
      "LR L2 regularization: vocab size: 2085\n",
      "\n",
      "-----------------\n",
      "C =  50.0\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.2944\n",
      "LR L2 regularization: f1_score = 0.2565\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 2207\n",
      "LR L2 regularization: number of non-zero weights = 4244\n",
      "\n",
      "LR L1 regularization: accuracy = 64.39%\n",
      "LR L2 regularization: accuracy = 66.51%\n",
      "\n",
      "***Re-trained model w/ L1 non-zero features***\n",
      "LR L2 regularization: f1_score = 0.0304\n",
      "LR L2 regularization: number of non-zero weights: 2207\n",
      "LR L2 regularization: accuracy = 73.70%\n",
      "\n",
      "LR L2 regularization: vocab size: 2207\n",
      "\n",
      "-----------------\n",
      "C =  70.0\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.2857\n",
      "LR L2 regularization: f1_score = 0.2624\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 2292\n",
      "LR L2 regularization: number of non-zero weights = 4244\n",
      "\n",
      "LR L1 regularization: accuracy = 63.44%\n",
      "LR L2 regularization: accuracy = 65.86%\n",
      "\n",
      "***Re-trained model w/ L1 non-zero features***\n",
      "LR L2 regularization: f1_score = 0.0304\n",
      "LR L2 regularization: number of non-zero weights: 2292\n",
      "LR L2 regularization: accuracy = 73.70%\n",
      "\n",
      "LR L2 regularization: vocab size: 2292\n",
      "\n",
      "-----------------\n",
      "C =  100.0\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.2828\n",
      "LR L2 regularization: f1_score = 0.2743\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 2365\n",
      "LR L2 regularization: number of non-zero weights = 4244\n",
      "\n",
      "LR L1 regularization: accuracy = 62.91%\n",
      "LR L2 regularization: accuracy = 65.68%\n",
      "\n",
      "***Re-trained model w/ L1 non-zero features***\n",
      "LR L2 regularization: f1_score = 0.0304\n",
      "LR L2 regularization: number of non-zero weights: 2365\n",
      "LR L2 regularization: accuracy = 73.64%\n",
      "\n",
      "LR L2 regularization: vocab size: 2365\n",
      "\n",
      "-----------------\n",
      "C =  200.0\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.2848\n",
      "LR L2 regularization: f1_score = 0.2722\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 2449\n",
      "LR L2 regularization: number of non-zero weights = 4244\n",
      "\n",
      "LR L1 regularization: accuracy = 62.09%\n",
      "LR L2 regularization: accuracy = 64.68%\n",
      "\n",
      "***Re-trained model w/ L1 non-zero features***\n",
      "LR L2 regularization: f1_score = 0.0304\n",
      "LR L2 regularization: number of non-zero weights: 2449\n",
      "LR L2 regularization: accuracy = 73.64%\n",
      "\n",
      "LR L2 regularization: vocab size: 2449\n",
      "\n",
      "-----------------\n",
      "C =  300.0\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.2904\n",
      "LR L2 regularization: f1_score = 0.2744\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 2589\n",
      "LR L2 regularization: number of non-zero weights = 4244\n",
      "\n",
      "LR L1 regularization: accuracy = 61.38%\n",
      "LR L2 regularization: accuracy = 64.45%\n",
      "\n",
      "***Re-trained model w/ L1 non-zero features***\n",
      "LR L2 regularization: f1_score = 0.2889\n",
      "LR L2 regularization: number of non-zero weights: 2589\n",
      "LR L2 regularization: accuracy = 65.74%\n",
      "\n",
      "LR L2 regularization: vocab size: 2589\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEZCAYAAABiu9n+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nARSLGbBjnOOBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116156510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define function fs (feature selection)\n",
    "\n",
    "def fs():\n",
    "    # Keep this random seed here to make comparison easier.\n",
    "    \n",
    "    # create two empty vectors\n",
    "    accuracies = []\n",
    "    vocab_size = []\n",
    "    \n",
    "    ### STUDENT START ###\n",
    "\n",
    "    ### Logistic regression seeks the set of weights that minimizes errors in the training data AND has a small size.\n",
    "    ### For this size, the default regularization, L2, computes the sum of the squared weights (see P3, above), while \n",
    "    ### L1 regularization computes the sum of the absolute values of the weights. \n",
    "    ### L2 regularization makes all the weights relatively small, whereas\n",
    "    ### L1 regularization drives lots of the weights to 0, effectively removing unimportant features [for feature selection].\n",
    "\n",
    "    ### http://scikit-learn.org/stable/auto_examples/linear_model/plot_logistic_l1_l2_sparsity.html\n",
    "     \n",
    "    # set min_df=10 to ignore words that appear in less than 10 documents\n",
    "    # use stop_words='english' to remove less meaningful words from the resulting tokens, only applies if default analyzer='word'.\n",
    "\n",
    "    vectorizer = TfidfVectorizer(min_df=1, stop_words='english')\n",
    "    #vectorizer = CountVectorizer(min_df=1, stop_words='english')\n",
    "    train_vectors = vectorizer.fit_transform(train_text)\n",
    "    dev_vectors = vectorizer.transform(dev_text)    \n",
    "    \n",
    "    cs = [0.01, 0.03, 0.05, 0.07, 0.1, 0.3, 0.5, 0.57, 0.7, 1, 10, 12, 30, 50, 70, 100, 200, 300]\n",
    "    # no longer use np.linspace to return evenly spaced numbers over a specified interval.\n",
    "    # it offers less control.\n",
    "    \n",
    "    for c in cs:\n",
    "\n",
    "        # fit l1 and l2 models\n",
    "        lr_l1 = LogisticRegression(C=c, penalty='l1', tol=0.01)\n",
    "        lr_l2 = LogisticRegression(C=c, penalty='l2', tol=0.01)\n",
    "        lr_l1.fit(train_vectors, train_labels)\n",
    "        lr_l2.fit(train_vectors, train_labels)\n",
    "        \n",
    "        # store predictions\n",
    "        pred_l1 = lr_l1.predict(dev_vectors)\n",
    "        pred_l2 = lr_l2.predict(dev_vectors)\n",
    "        \n",
    "        print \"-----------------\"\n",
    "        print \"C = \", round(c,3)\n",
    "        print \"-----------------\"\n",
    "        \n",
    "        print \"LR L1 regularization: f1_score = %s\" % (round(metrics.f1_score(dev_labels, pred_l1, average='binary'),4))\n",
    "        print \"LR L2 regularization: f1_score = %s\" % (round(metrics.f1_score(dev_labels, pred_l2, average='binary'),4))\n",
    "        print\n",
    "        \n",
    "        #print \"lr_l1.coef_:\", lr_l1.coef_\n",
    "        #print \"lr_l2.coef_:\", lr_l2.coef_\n",
    "        \n",
    "        # take mean weight for each class\n",
    "        # axis=0 refers to mean of each column across 4 rows in coef_\n",
    "        # use as definition of sparsity\n",
    "        vec1 = np.mean(lr_l1.coef_, axis=0)\n",
    "        vec2 = np.mean(lr_l2.coef_, axis=0)\n",
    "        \n",
    "        #print \"vec1:\", vec1\n",
    "        #print \"vec2:\", vec2\n",
    "        \n",
    "        print \"LR L1 regularization: number of non-zero weights =\", (vec1 != 0).sum()\n",
    "        print \"LR L2 regularization: number of non-zero weights =\", (vec2 != 0).sum()\n",
    "        print \n",
    "        \n",
    "        # http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.score\n",
    "        # score(X, y, sample_weight=None)\n",
    "        # Returns the mean accuracy on the given dev or test data and labels\n",
    "        # In multi-label classification, this is the subset accuracy which is a harsh metric \n",
    "        # since you require for each sample that each label set be correctly predicted.\n",
    "        \n",
    "        print \"LR L1 regularization: accuracy = %.2f%%\" % ((lr_l1.score(dev_vectors, dev_labels))*100)\n",
    "        print \"LR L2 regularization: accuracy = %.2f%%\" % ((lr_l2.score(dev_vectors, dev_labels))*100)\n",
    "        print\n",
    "        \n",
    "        #print \"recheck\", train_vectors.shape\n",
    "        #print \"recheck\", train_labels.shape\n",
    "        \n",
    "        #---------------\n",
    "        # re-train model\n",
    "        #---------------\n",
    "        \n",
    "        # likely no need to use fit_transform again, as we still have our vocabulary in matrix format with token counts.\n",
    "        # we simply select non-zero weighted features (from columns), and leave documents (from rows) as is.\n",
    "        \n",
    "        # first, only select features that have non-zero weights from L1 regularization.\n",
    "        # vec1 includes weights for each feature (column).\n",
    "        train_vectors_rt = train_vectors[:, vec1 != 0]\n",
    "        dev_vectors_rt = dev_vectors[:, vec1 != 0]\n",
    "        \n",
    "        #print train_vectors_rt\n",
    "        \n",
    "        #print \"recheck\", train_vectors_rt.shape\n",
    "        #print \"recheck\", train_labels.shape\n",
    "        \n",
    "        lr_l2_rt = LogisticRegression(C=c, penalty='l2', tol=0.1)\n",
    "    \n",
    "        # refit our classifier to the model, so it can learn from the model\n",
    "        # if the number of features >= 1 from L1 for L2\n",
    "        if train_vectors_rt.shape[1] >= 1:\n",
    "        \n",
    "            lr_l2_rt.fit(train_vectors_rt, train_labels)\n",
    "            pred_l2_rt = lr_l2_rt.predict(dev_vectors_rt)\n",
    "\n",
    "            # take mean weight for each class\n",
    "            # axis=0 refers to mean of each column across 4 rows in coef_\n",
    "            # use as definition of sparsity\n",
    "            vec_rt = np.mean(lr_l2_rt.coef_, axis=0)\n",
    "\n",
    "            # append to vectors\n",
    "            # note: try .score method (mean accuracy on the given test data and labels) rather than f1_score method,\n",
    "            #        partly because sometimes the output cell shows a system automated warning about the f1_score\n",
    "            accuracies.append((lr_l2_rt.score(dev_vectors_rt, dev_labels))*100)  \n",
    "            vocab_size.append(train_vectors_rt.shape[1])\n",
    "\n",
    "            print \"***Re-trained model w/ L1 non-zero features***\" \n",
    "            print \"LR L2 regularization: f1_score = %s\" % (round(metrics.f1_score(dev_labels, pred_l2_rt, average='binary'),4))\n",
    "            print \"LR L2 regularization: number of non-zero weights:\", (vec_rt != 0).sum()\n",
    "            print \"LR L2 regularization: accuracy = %.2f%%\" % ((lr_l2_rt.score(dev_vectors_rt, dev_labels))*100)\n",
    "            print\n",
    "            print \"LR L2 regularization: vocab size:\", (train_vectors_rt.shape[1])\n",
    "            print\n",
    "\n",
    "        #print accuracies\n",
    "        #print vocab_size\n",
    "        #print\n",
    "    \n",
    "    plt.scatter(vocab_size, accuracies)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Vocabulary Size')\n",
    "    plt.title('Relationship between Accuracy and Vocabulary Size')\n",
    "\n",
    "    ### STUDENT END ###\n",
    "fs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 4244\n",
      "\n",
      "[[ 0.06781199  0.93218801]\n",
      " [ 0.84691572  0.15308428]\n",
      " [ 0.99885842  0.00114158]\n",
      " ..., \n",
      " [ 0.99488125  0.00511875]\n",
      " [ 0.81469857  0.18530143]\n",
      " [ 0.5510308   0.4489692 ]]\n",
      "************************************************\n",
      "\n",
      "dev indices of top 3 R_rates: [492, 532, 1281]\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "W207 Results\n",
      "------------\n",
      "R_rate: 77650.5251589\n",
      "label probabilities: [  9.99987122e-01   1.28780471e-05]\n",
      "Max probability dev_label -> False\n",
      "Correct dev_label -> True\n",
      "dev_text below:\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "[REQUEST] I'll give a two week xbox live code for a slice of pie!\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "W207 Results\n",
      "------------\n",
      "R_rate: 43068.2957014\n",
      "label probabilities: [  9.99976782e-01   2.32183969e-05]\n",
      "Max probability dev_label -> False\n",
      "Correct dev_label -> True\n",
      "dev_text below:\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "[Request] Been broke for half a month, almost completely out of food. Really, really want a pizza.\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "W207 Results\n",
      "------------\n",
      "R_rate: 21780.5744864\n",
      "label probabilities: [  9.99954090e-01   4.59103634e-05]\n",
      "Max probability dev_label -> False\n",
      "Correct dev_label -> True\n",
      "dev_text below:\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "[Request] Tulsa, OK Recently graduated, unemployed student.\n",
      "\n",
      "************************************************\n",
      "\n",
      "dev indices of bottom 3 R_rates: [0, 7, 13]\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "W207 Results\n",
      "------------\n",
      "R_rate: 1.0\n",
      "label probabilities: [ 0.06781199  0.93218801]\n",
      "Max probability dev_label -> True\n",
      "Correct dev_label -> True\n",
      "dev_text below:\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "[REQUEST] Southern Arizona, Tucson Hungry Family\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "W207 Results\n",
      "------------\n",
      "R_rate: 1.0\n",
      "label probabilities: [ 0.23096789  0.76903211]\n",
      "Max probability dev_label -> True\n",
      "Correct dev_label -> True\n",
      "dev_text below:\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "[Request] New to this, not sure how it works\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "W207 Results\n",
      "------------\n",
      "R_rate: 1.0\n",
      "label probabilities: [ 0.37540096  0.62459904]\n",
      "Max probability dev_label -> True\n",
      "Correct dev_label -> True\n",
      "dev_text below:\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "[request] Pennsylvnia USA Would love to have pizza night for me and my daughter\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:56: DeprecationWarning: using a boolean instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "# define function fs2 (feature selection, method 2)\n",
    "\n",
    "def fs2():\n",
    "    \n",
    "    ### STUDENT START ###\n",
    "    \n",
    "    # CountVectorizer:\n",
    "    # Tokenize the documents and count the occurrences of token and return them as a sparse matrix\n",
    "\n",
    "    # TfidfTransformer:\n",
    "    # Apply Term Frequency Inverse Document Frequency normalization to a sparse matrix of occurrence counts\n",
    "    \n",
    "    # Tf means term-frequency while tf-idf means term-frequency times inverse document-frequency\n",
    "    # This is a common term weighting scheme in information retrieval, \n",
    "    # that has also found good use in document classification.\n",
    "    # The goal of using tf-idf instead of the raw frequencies of occurrence of a token in a given document is to \n",
    "    # scale down the impact of tokens that occur very frequently in a given corpus and that are hence empirically \n",
    "    # less informative than features that occur in a small fraction of the training corpus.\n",
    "\n",
    "    vectorizer = TfidfVectorizer(min_df=1, stop_words='english')\n",
    "    \n",
    "    # apply the CountVectorizer fit_transform method -- which includes two methods in one -- on the train_text.\n",
    "    # learn the vocabulary dictionary (all tokens from the raw documents) and return a matrix, \n",
    "    # extracting token counts to the cells.\n",
    "    train_vectors = vectorizer.fit_transform(train_text)\n",
    "    \n",
    "    # apply the transform method to the dev_text\n",
    "    dev_vectors = vectorizer.transform(dev_text)\n",
    "    \n",
    "    # transform train_text to matrix and print count of rows and columns\n",
    "    # 2034 documents, 3064 words\n",
    "    print \"vocabulary size:\", train_vectors.toarray().shape[1] \n",
    "    print\n",
    "    \n",
    "    lr = LogisticRegression(penalty='l2', C=100)\n",
    "    lr.fit(train_vectors, train_labels)\n",
    "    pred_4 = lr.predict(dev_vectors)\n",
    "\n",
    "    # for each documents, store and print predicted probabilities that it belongs to each class\n",
    "    \n",
    "    # use the method, predict_proba\n",
    "    \n",
    "    # for each document in dev_vectors, get their probability estimates for all classes \n",
    "    p = lr.predict_proba(dev_vectors)\n",
    "    print p\n",
    "\n",
    "    # create an empty vector\n",
    "    \n",
    "    p_max_rates = []\n",
    "    R_rates = []\n",
    "    \n",
    "    # iterate over each row (document) of p\n",
    "    for i, p_docs in enumerate(p):\n",
    "        # p_docs is a 1x2 vector from p with a document's probability to each class on one row\n",
    "        # take the document's probability of the correct label\n",
    "        p_correct_class = p_docs[dev_labels[i]]\n",
    "        # take the document's max probability across the 4 labels\n",
    "        p_max = p_docs.max()\n",
    "\n",
    "        p_max_rates.append(p_max)\n",
    "        \n",
    "        # calculate R\n",
    "        R = p_max / p_correct_class\n",
    "\n",
    "        # append to the R_rates vector\n",
    "        R_rates.append(R)\n",
    "\n",
    "    # create vector that have indices of top 3 R_rates\n",
    "    top3_index = sorted(range(dev_vectors.shape[0]), key=lambda i: R_rates[i], reverse=True)[:3]\n",
    "    print \"************************************************\"\n",
    "    print\n",
    "    print \"dev indices of top 3 R_rates:\", top3_index\n",
    "    print\n",
    "\n",
    "    adhoc_label = ['False','True']\n",
    "    \n",
    "    for i in top3_index:\n",
    "        \n",
    "        # find index of max probability within each row\n",
    "        # np.argmax returns the indices of the maximum values along an axis\n",
    "        index_max_prob = np.argmax(p[i,:])\n",
    "                                   \n",
    "        print \"---------------------------------------------------------------------\"\n",
    "        print \"W207 Results\"\n",
    "        print \"------------\"\n",
    "        print \"R_rate:\", R_rates[i]\n",
    "        print \"label probabilities:\", p[i,:]\n",
    "        print \"Max probability dev_label -> %s\" % (adhoc_label[index_max_prob])\n",
    "        print \"Correct dev_label -> %s\" % (dev_labels[i])\n",
    "        print \"dev_text below:\"\n",
    "        print \"---------------------------------------------------------------------\"\n",
    "        print\n",
    "        print dev_text[i]\n",
    "        print\n",
    "\n",
    "    # create vector that have indices of bottom 3 R_rates\n",
    "    bottom3_index = sorted(range(dev_vectors.shape[0]), key=lambda i: R_rates[i])[:3]\n",
    "    print \"************************************************\"\n",
    "    print\n",
    "    print \"dev indices of bottom 3 R_rates:\", bottom3_index\n",
    "    print\n",
    "    \n",
    "    for i in bottom3_index:\n",
    "        \n",
    "        # find index of max probability within each row\n",
    "        # np.argmax returns the indices of the maximum values along an axis\n",
    "        index_max_prob = np.argmax(p[i,:])\n",
    "                                   \n",
    "        print \"---------------------------------------------------------------------\"\n",
    "        print \"W207 Results\"\n",
    "        print \"------------\"\n",
    "        print \"R_rate:\", R_rates[i]\n",
    "        print \"label probabilities:\", p[i,:]\n",
    "        print \"Max probability dev_label -> %s\" % (adhoc_label[index_max_prob])\n",
    "        print \"Correct dev_label -> %s\" % (dev_labels[i])\n",
    "        print \"dev_text below:\"\n",
    "        print \"---------------------------------------------------------------------\"\n",
    "        print\n",
    "        print dev_text[i]\n",
    "        print\n",
    "        \n",
    "        \n",
    "    ### STUDENT END ###\n",
    "fs2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
