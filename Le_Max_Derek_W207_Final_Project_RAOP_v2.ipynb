{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Acts of Pizza (RAOP) Notes\n",
    "\n",
    "**Source**: Althoff, T., Danescu-Niculescu-Mizil, C., & Jurafsky, D. (2014). *How to Ask for a Favor: A Case Study on the Success of Altruistic Requests*. Association for the Advancement of Artificial\n",
    "Intelligence (www.aaai.org).\n",
    "\n",
    "- \"The community only publishes which users have given or received pizzas but not which requests were successful. \n",
    "In the case of successful users posting multiple times it is unclear which of the requests was actually successful. \n",
    "Therefore, we restrict our analysis to users with a single request for which we can be certain whether or not \n",
    "it was successful, leaving us with 5728 pizza requests. We split this dataset into development(70%) and test set (30%) \n",
    "such that both sets mirror the average success rate in our dataset of 24.6%. All features are developed on the \n",
    "development test only while the test set is used only once to evaluate the prediction accuracy of our proposed model on held-out data. For a small number of requests (379) we further observe the identity of the benefactor through a \n",
    "'thank you' post by the beneficiary after the successful request. This enables us to reason about the impact of \n",
    "user similarity on giving.\"\n",
    "\n",
    "\n",
    "- \"It is extremely difficult to disentangle the effects of all these factors in determining what makes people satisfy requests, and what makes them select some requests over others. . . In this paper, we develop a framework for controlling for each of these potential confounds while studying the role of two aspects that characterize compelling requests: **social factors** (who is asking and how the recipient is related to the donor and community) and **linguistic factors** (how they are asking and what linguistic devices accompany successful requests). With the notable exception of Mitra and Gilbert (2014), the effect of language on the success of requests has largely been ignored thus far.\"\n",
    "\n",
    "\n",
    "- \"[Their] goal is to understand what motivates people to give when they do not receive anything tangible in return. That is, [they] focus on the important special case of altruistic requests in which the giver receives no rewards.\" **DSC**: But how do you know people don't want something in return, especially if they are more likely to help requesters who have high status or are more similar to them?\n",
    "\n",
    "-----\n",
    "\n",
    "Temporal Factors\n",
    "- Specific months\n",
    "- Weekdays\n",
    "- **Days of the month (first half of the month)**\n",
    "- Hour of the day\n",
    "- **Community age of the request (earlier the better)**\n",
    "\n",
    "Textual Factors\n",
    "- Politeness (e.g., **gratitude**)\n",
    "- **Evidentiality** (2nd largest parameter estimate)\n",
    "- Reciprocity (respond to a positive action with another positive action, **pay it forward**)\n",
    "- Sentiment (e.g., **urgency**)\n",
    "- **Length**\n",
    "\n",
    "Social Factors\n",
    "- **Status**\n",
    "    - karma points (up-votes minus down-votes) that Reddit counts on link submissions and comments,\n",
    "    - user has posted on RAOP before and thus could be considered a member of the sub-community. \n",
    "    - **user account age based on the hypothesis that “younger” accounts might be less trusted**\n",
    "\n",
    "\n",
    "- Similarity: intersection size between the set of the giver and receiver, and the Jaccard similarity (intersection\n",
    "over union) of the two. NOT included in logistic regression model.\n",
    "\n",
    "Narratives (identified through topic modeling)\n",
    "- **Desire**\n",
    "- **Family**\n",
    "- **Job**\n",
    "- **Money**\n",
    "- Student\n",
    "\n",
    "-----\n",
    "\n",
    "Conclusion\n",
    "- Drawing from social psychology literature [they] extract high-level social features from text that operationalize the relation between recipient and donor and demonstrate that these extracted relations are predictive of success. \n",
    "- [They] show that [they] can detect key narratives automatically that have significant impact on the success of the request. \n",
    "- [They] further demonstrate that linguistic indications of gratitude, evidentiality, and reciprocity, as well as the high status of the asker, all increase the likelihood of success, while neither politeness nor positive sentiment seem to be associated with success in [the] setting.\n",
    "\n",
    "Limitations\n",
    "- A shortcoming of any case study is that findings might be specific to the scenario at hand. While [they] have shown that particular linguistic and social factors differentiate between successful and unsuccessful requests [they] cannot claim a causal relationship between the proposed factors and success that would guarantee success. \n",
    "- Furthermore, the set of success factors studied in this work is likely to be incomplete as well and excludes,\n",
    "for instance, group behavior dynamics. \n",
    "- Despite these limitations, [they] hope that this work and the data [they] make available will provide a basis for further research on success factors and helping behavior in other online communities.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import codecs\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'requester_received_pizza']\n",
      "(3975, 1)\n",
      "\n",
      "[u'giver_username_if_known', u'in_test_set', u'number_of_downvotes_of_request_at_retrieval', u'number_of_upvotes_of_request_at_retrieval', u'post_was_edited', u'request_id', u'request_number_of_comments_at_retrieval', u'request_text', u'request_text_edit_aware', u'request_title', u'requester_account_age_in_days_at_request', u'requester_account_age_in_days_at_retrieval', u'requester_days_since_first_post_on_raop_at_request', u'requester_days_since_first_post_on_raop_at_retrieval', u'requester_number_of_comments_at_request', u'requester_number_of_comments_at_retrieval', u'requester_number_of_comments_in_raop_at_request', u'requester_number_of_comments_in_raop_at_retrieval', u'requester_number_of_posts_at_request', u'requester_number_of_posts_at_retrieval', u'requester_number_of_posts_on_raop_at_request', u'requester_number_of_posts_on_raop_at_retrieval', u'requester_number_of_subreddits_at_request', u'requester_subreddits_at_request', u'requester_upvotes_minus_downvotes_at_request', u'requester_upvotes_minus_downvotes_at_retrieval', u'requester_upvotes_plus_downvotes_at_request', u'requester_upvotes_plus_downvotes_at_retrieval', u'requester_user_flair', u'requester_username', u'unix_timestamp_of_request', u'unix_timestamp_of_request_utc']\n",
      "(3975, 32)\n",
      "\n",
      "[u'requester_received_pizza']\n",
      "(1696, 1)\n",
      "\n",
      "[u'giver_username_if_known', u'in_test_set', u'number_of_downvotes_of_request_at_retrieval', u'number_of_upvotes_of_request_at_retrieval', u'post_was_edited', u'request_id', u'request_number_of_comments_at_retrieval', u'request_text', u'request_text_edit_aware', u'request_title', u'requester_account_age_in_days_at_request', u'requester_account_age_in_days_at_retrieval', u'requester_days_since_first_post_on_raop_at_request', u'requester_days_since_first_post_on_raop_at_retrieval', u'requester_number_of_comments_at_request', u'requester_number_of_comments_at_retrieval', u'requester_number_of_comments_in_raop_at_request', u'requester_number_of_comments_in_raop_at_retrieval', u'requester_number_of_posts_at_request', u'requester_number_of_posts_at_retrieval', u'requester_number_of_posts_on_raop_at_request', u'requester_number_of_posts_on_raop_at_retrieval', u'requester_number_of_subreddits_at_request', u'requester_subreddits_at_request', u'requester_upvotes_minus_downvotes_at_request', u'requester_upvotes_minus_downvotes_at_retrieval', u'requester_upvotes_plus_downvotes_at_request', u'requester_upvotes_plus_downvotes_at_retrieval', u'requester_user_flair', u'requester_username', u'unix_timestamp_of_request', u'unix_timestamp_of_request_utc']\n",
      "(1696, 32)\n",
      "\n",
      "requester_received_pizza    0.241006\n",
      "dtype: float64\n",
      "\n",
      "requester_received_pizza    0.258844\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_json.html\n",
    "# Convert a JSON string to pandas object\n",
    "\n",
    "X = pd.read_json('./pizza_request_dataset.json')\n",
    "#print X.head()\n",
    "#print X.describe()\n",
    "#print\n",
    "\n",
    "'''\n",
    "shuffle = np.random.permutation(np.arange(d.shape[0]))\n",
    "\n",
    "print shuffle.max()\n",
    "\n",
    "print X['giver_username_if_known'][:2]\n",
    "X = X.sample(frac=1) #.reset_index(drop=True)\n",
    "print X['giver_username_if_known'][:2]\n",
    "\n",
    "#X, Y = X[shuffle], Y[shuffle]\n",
    "'''\n",
    "\n",
    "np.random.seed(0)\n",
    "msk = np.random.rand(len(X)) <= 0.7\n",
    "X_train_data = X[msk]\n",
    "X_dev_data = X[~msk]\n",
    "\n",
    "Y_train_labels = X_train_data[[\"requester_received_pizza\"]]\n",
    "#Y.describe()\n",
    "\n",
    "del X_train_data[\"requester_received_pizza\"]\n",
    "\n",
    "print list(Y_train_labels)\n",
    "print Y_train_labels.shape\n",
    "print\n",
    "print list(X_train_data)\n",
    "print X_train_data.shape\n",
    "print\n",
    "\n",
    "Y_dev_labels = X_dev_data[[\"requester_received_pizza\"]]\n",
    "#Y.describe()\n",
    "\n",
    "del X_dev_data[\"requester_received_pizza\"]\n",
    "\n",
    "print list(Y_dev_labels)\n",
    "print Y_dev_labels.shape\n",
    "print\n",
    "print list(X_dev_data)\n",
    "print X_dev_data.shape\n",
    "print\n",
    "\n",
    "print np.mean(Y_train_labels)\n",
    "print\n",
    "print np.mean(Y_dev_labels)\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef read_dataset(path):\\n    with codecs.open(path, 'r', 'utf-8') as myFile:\\n        content = myFile.read()\\n    dataset = json.loads(content)\\n    return dataset\\n\\nif __name__ == '__main__':\\n    path = './pizza_request_dataset.json'\\n    dataset = read_dataset(path)\\n    \\n    print 'The dataset contains %d samples.' %(len(dataset))\\n    print\\n    print 'Available attributes: ', sorted(dataset[0].keys())\\n    print\\n    \\n    for i in range(3):\\n        print '---------'\\n        print 'Post:', i\\n        print '---------'\\n        print json.dumps(dataset[i], sort_keys=True, indent=2)\\n        print\\n    \\n    successes = [r['requester_received_pizza'] for r in dataset]\\n    success_rate = 100.0 * sum(successes) / float(len(successes))\\n    print 'The average success rate is: %.2f%%' %(success_rate)\\n    print\\n\\ndef read_dataset_pd(path):\\n    with codecs.open(path, 'r', 'utf-8') as myFile:\\n        content = myFile.read()\\n        \\n    json_data = json.load(open(content))\\n    df = pandas.io.json.json_normalize(json_data)\\n    print df.head()\\n    \\nread_dataset_pd(path)\\n\\n#read_dataset_pd('./pizza_request_dataset.json')\\n\\ndef read_narrative(path, vector):\\n    temp = open(path)\\n    vector = []\\n    for word in temp:\\n        vector.append(word.rstrip())\\n    print vector\\n    print\\n    \\n#read_narrative('./narratives/desire.txt', desire)\\n\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def read_dataset(path):\n",
    "    with codecs.open(path, 'r', 'utf-8') as myFile:\n",
    "        content = myFile.read()\n",
    "    dataset = json.loads(content)\n",
    "    return dataset\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    path = './pizza_request_dataset.json'\n",
    "    dataset = read_dataset(path)\n",
    "    \n",
    "    print 'The dataset contains %d samples.' %(len(dataset))\n",
    "    print\n",
    "    print 'Available attributes: ', sorted(dataset[0].keys())\n",
    "    print\n",
    "    \n",
    "    for i in range(3):\n",
    "        print '---------'\n",
    "        print 'Post:', i\n",
    "        print '---------'\n",
    "        print json.dumps(dataset[i], sort_keys=True, indent=2)\n",
    "        print\n",
    "    \n",
    "    successes = [r['requester_received_pizza'] for r in dataset]\n",
    "    success_rate = 100.0 * sum(successes) / float(len(successes))\n",
    "    print 'The average success rate is: %.2f%%' %(success_rate)\n",
    "    print\n",
    "\n",
    "def read_dataset_pd(path):\n",
    "    with codecs.open(path, 'r', 'utf-8') as myFile:\n",
    "        content = myFile.read()\n",
    "        \n",
    "    json_data = json.load(open(content))\n",
    "    df = pandas.io.json.json_normalize(json_data)\n",
    "    print df.head()\n",
    "    \n",
    "read_dataset_pd(path)\n",
    "\n",
    "#read_dataset_pd('./pizza_request_dataset.json')\n",
    "\n",
    "def read_narrative(path, vector):\n",
    "    temp = open(path)\n",
    "    vector = []\n",
    "    for word in temp:\n",
    "        vector.append(word.rstrip())\n",
    "    print vector\n",
    "    print\n",
    "    \n",
    "#read_narrative('./narratives/desire.txt', desire)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
