{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Acts of Pizza (RAOP) Notes\n",
    "\n",
    "**Source**: Althoff, T., Danescu-Niculescu-Mizil, C., & Jurafsky, D. (2014). *How to Ask for a Favor: A Case Study on the Success of Altruistic Requests*. Association for the Advancement of Artificial\n",
    "Intelligence (www.aaai.org).\n",
    "\n",
    "- \"The community only publishes which users have given or received pizzas but not which requests were successful. \n",
    "In the case of successful users posting multiple times it is unclear which of the requests was actually successful. \n",
    "Therefore, we restrict our analysis to users with a single request for which we can be certain whether or not \n",
    "it was successful, leaving us with 5728 pizza requests. We split this dataset into development(70%) and test set (30%) \n",
    "such that both sets mirror the average success rate in our dataset of 24.6%. All features are developed on the \n",
    "development test only while the test set is used only once to evaluate the prediction accuracy of our proposed model on held-out data. For a small number of requests (379) we further observe the identity of the benefactor through a \n",
    "'thank you' post by the beneficiary after the successful request. This enables us to reason about the impact of \n",
    "user similarity on giving.\"\n",
    "\n",
    "\n",
    "- \"It is extremely difficult to disentangle the effects of all these factors in determining what makes people satisfy requests, and what makes them select some requests over others. . . In this paper, we develop a framework for controlling for each of these potential confounds while studying the role of two aspects that characterize compelling requests: **social factors** (who is asking and how the recipient is related to the donor and community) and **linguistic factors** (how they are asking and what linguistic devices accompany successful requests). With the notable exception of Mitra and Gilbert (2014), the effect of language on the success of requests has largely been ignored thus far.\"\n",
    "\n",
    "\n",
    "- \"[Their] goal is to understand what motivates people to give when they do not receive anything tangible in return. That is, [they] focus on the important special case of altruistic requests in which the giver receives no rewards.\" **DSC**: But how do you know people don't want something in return, especially if they are more likely to help requesters who have high status or are more similar to them?\n",
    "\n",
    "-----\n",
    "\n",
    "Temporal Factors\n",
    "- Specific months\n",
    "- Weekdays\n",
    "- **Days of the month (first half of the month)**\n",
    "- Hour of the day\n",
    "- **Community age of the request (earlier the better)**\n",
    "\n",
    "Textual Factors\n",
    "- Politeness (e.g., **gratitude**)\n",
    "- **Evidentiality** (2nd largest parameter estimate)\n",
    "- Reciprocity (respond to a positive action with another positive action, **pay it forward**)\n",
    "- Sentiment (e.g., **urgency**)\n",
    "- **Length**\n",
    "\n",
    "Social Factors\n",
    "- **Status**\n",
    "    - karma points (up-votes minus down-votes) that Reddit counts on link submissions and comments,\n",
    "    - user has posted on RAOP before and thus could be considered a member of the sub-community. \n",
    "    - **user account age based on the hypothesis that “younger” accounts might be less trusted**\n",
    "\n",
    "\n",
    "- Similarity: intersection size between the set of the giver and receiver, and the Jaccard similarity (intersection\n",
    "over union) of the two. NOT included in logistic regression model.\n",
    "\n",
    "Narratives (identified through topic modeling)\n",
    "- **Desire**\n",
    "- **Family**\n",
    "- **Job**\n",
    "- **Money**\n",
    "- Student\n",
    "\n",
    "-----\n",
    "\n",
    "Conclusion\n",
    "- Drawing from social psychology literature [they] extract high-level social features from text that operationalize the relation between recipient and donor and demonstrate that these extracted relations are predictive of success. \n",
    "- [They] show that [they] can detect key narratives automatically that have significant impact on the success of the request. \n",
    "- [They] further demonstrate that linguistic indications of gratitude, evidentiality, and reciprocity, as well as the high status of the asker, all increase the likelihood of success, while neither politeness nor positive sentiment seem to be associated with success in [the] setting.\n",
    "\n",
    "Limitations\n",
    "- A shortcoming of any case study is that findings might be specific to the scenario at hand. While [they] have shown that particular linguistic and social factors differentiate between successful and unsuccessful requests [they] cannot claim a causal relationship between the proposed factors and success that would guarantee success. \n",
    "- Furthermore, the set of success factors studied in this work is likely to be incomplete as well and excludes,\n",
    "for instance, group behavior dynamics. \n",
    "- Despite these limitations, [they] hope that this work and the data [they] make available will provide a basis for further research on success factors and helping behavior in other online communities.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import codecs\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_labels\n",
      "----------\n",
      "[u'requester_received_pizza']\n",
      "(3975, 1)\n",
      "\n",
      "train_data\n",
      "----------\n",
      "[u'giver_username_if_known', u'in_test_set', u'number_of_downvotes_of_request_at_retrieval', u'number_of_upvotes_of_request_at_retrieval', u'post_was_edited', u'request_id', u'request_number_of_comments_at_retrieval', u'request_text', u'request_text_edit_aware', u'request_title', u'requester_account_age_in_days_at_request', u'requester_account_age_in_days_at_retrieval', u'requester_days_since_first_post_on_raop_at_request', u'requester_days_since_first_post_on_raop_at_retrieval', u'requester_number_of_comments_at_request', u'requester_number_of_comments_at_retrieval', u'requester_number_of_comments_in_raop_at_request', u'requester_number_of_comments_in_raop_at_retrieval', u'requester_number_of_posts_at_request', u'requester_number_of_posts_at_retrieval', u'requester_number_of_posts_on_raop_at_request', u'requester_number_of_posts_on_raop_at_retrieval', u'requester_number_of_subreddits_at_request', u'requester_subreddits_at_request', u'requester_upvotes_minus_downvotes_at_request', u'requester_upvotes_minus_downvotes_at_retrieval', u'requester_upvotes_plus_downvotes_at_request', u'requester_upvotes_plus_downvotes_at_retrieval', u'requester_user_flair', u'requester_username', u'unix_timestamp_of_request', u'unix_timestamp_of_request_utc']\n",
      "(3975, 32)\n",
      "\n",
      "dev_labels\n",
      "----------\n",
      "[u'requester_received_pizza']\n",
      "(1696, 1)\n",
      "\n",
      "dev_data\n",
      "----------\n",
      "[u'giver_username_if_known', u'in_test_set', u'number_of_downvotes_of_request_at_retrieval', u'number_of_upvotes_of_request_at_retrieval', u'post_was_edited', u'request_id', u'request_number_of_comments_at_retrieval', u'request_text', u'request_text_edit_aware', u'request_title', u'requester_account_age_in_days_at_request', u'requester_account_age_in_days_at_retrieval', u'requester_days_since_first_post_on_raop_at_request', u'requester_days_since_first_post_on_raop_at_retrieval', u'requester_number_of_comments_at_request', u'requester_number_of_comments_at_retrieval', u'requester_number_of_comments_in_raop_at_request', u'requester_number_of_comments_in_raop_at_retrieval', u'requester_number_of_posts_at_request', u'requester_number_of_posts_at_retrieval', u'requester_number_of_posts_on_raop_at_request', u'requester_number_of_posts_on_raop_at_retrieval', u'requester_number_of_subreddits_at_request', u'requester_subreddits_at_request', u'requester_upvotes_minus_downvotes_at_request', u'requester_upvotes_minus_downvotes_at_retrieval', u'requester_upvotes_plus_downvotes_at_request', u'requester_upvotes_plus_downvotes_at_retrieval', u'requester_user_flair', u'requester_username', u'unix_timestamp_of_request', u'unix_timestamp_of_request_utc']\n",
      "(1696, 32)\n",
      "\n",
      "train labels\n",
      "----------\n",
      "requester_received_pizza    0.241006\n",
      "dtype: float64\n",
      "\n",
      "dev labels\n",
      "----------\n",
      "requester_received_pizza    0.258844\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_json.html\n",
    "# Convert a JSON string to pandas object\n",
    "\n",
    "X = pd.read_json('./pizza_request_dataset.json')\n",
    "#print X.head()\n",
    "#print X.describe()\n",
    "#print\n",
    "\n",
    "'''\n",
    "shuffle = np.random.permutation(np.arange(d.shape[0]))\n",
    "\n",
    "print shuffle.max()\n",
    "\n",
    "print X['giver_username_if_known'][:2]\n",
    "X = X.sample(frac=1) #.reset_index(drop=True)\n",
    "print X['giver_username_if_known'][:2]\n",
    "\n",
    "#X, Y = X[shuffle], Y[shuffle]\n",
    "'''\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# randomly assign 70% to train_data, and 30% to dev_data\n",
    "msk = np.random.rand(len(X)) <= 0.7\n",
    "train_data = X[msk]\n",
    "dev_data = X[~msk]\n",
    "\n",
    "# create output dataframe Y of train_labels\n",
    "train_labels = train_data[[\"requester_received_pizza\"]]\n",
    "\n",
    "# delete train_labels from input dataframe of train_data\n",
    "del train_data[\"requester_received_pizza\"]\n",
    "\n",
    "# create output dataframe of dev_labels\n",
    "dev_labels = dev_data[[\"requester_received_pizza\"]]\n",
    "#Y.describe()\n",
    "\n",
    "# delete dev_labels from input dataframe of dev_data\n",
    "del dev_data[\"requester_received_pizza\"]\n",
    "\n",
    "# print labels and data\n",
    "print \"train_labels\" \n",
    "print \"----------\"\n",
    "print list(train_labels)\n",
    "print train_labels.shape\n",
    "print\n",
    "print \"train_data\" \n",
    "print \"----------\"\n",
    "print list(train_data)\n",
    "print train_data.shape\n",
    "print\n",
    "\n",
    "print \"dev_labels\" \n",
    "print \"----------\"\n",
    "print list(dev_labels)\n",
    "print dev_labels.shape\n",
    "print\n",
    "print \"dev_data\"\n",
    "print \"----------\"\n",
    "print list(dev_data)\n",
    "print dev_data.shape\n",
    "print\n",
    "\n",
    "# print percent of train_data and dev_data whose posts led to receipt of pizza\n",
    "print \"train labels\"\n",
    "print \"----------\"\n",
    "print np.mean(train_labels)\n",
    "print\n",
    "print \"dev labels\"\n",
    "print \"----------\"\n",
    "print np.mean(dev_labels)\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vectors.shape: (3975, 12313)\n",
      "dev_vectors.shape: (1696, 12313)\n",
      "\n",
      "------------------------------\n",
      "K Nearest Neighbors (K-NN)\n",
      "------------------------------\n",
      "K-NN: f1_score = 0.4133, k = 1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:54: DeprecationWarning: Passing additional arguments to the metric function as **kwargs is deprecated and will no longer be supported in 0.18. Use metric_params instead.\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-NN: f1_score = 0.0259, k = 5\n",
      "K-NN: f1_score = 0.0, k = 15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-NN: f1_score = 0.0, k = 16\n",
      "K-NN: f1_score = 0.0, k = 17"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-NN: f1_score = 0.0, k = 18\n",
      "K-NN: f1_score = 0.0, k = 19"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-NN: f1_score = 0.0, k = 20\n",
      "K-NN: f1_score = 0.0, k = 28"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-NN: f1_score = 0.0, k = 29\n",
      "K-NN: f1_score = 0.0, k = 30"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-NN: f1_score = 0.0, k = 31\n",
      "K-NN: f1_score = 0.0, k = 32"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-NN: f1_score = 0.0, k = 150\n",
      "K-NN: f1_score = 0.0, k = 300"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "K-NN: optimal k = 1\n",
      "\n",
      "-----------------------------\n",
      "Multinomial Naive Bayes (MNB)\n",
      "-----------------------------\n",
      "MNB: f1_score = 0.0907, alpha = 0.0\n",
      "MNB: f1_score = 0.1261, alpha = 1e-05\n",
      "MNB: f1_score = 0.1263, alpha = 0.0001\n",
      "MNB: f1_score = 0.1201, alpha = 0.001\n",
      "MNB: f1_score = 0.1032, alpha = 0.01\n",
      "MNB: f1_score = 0.0377, alpha = 0.094\n",
      "MNB: f1_score = 0.0377, alpha = 0.095\n",
      "MNB: f1_score = 0.0335, alpha = 0.096\n",
      "MNB: f1_score = 0.0337, alpha = 0.1\n",
      "MNB: f1_score = 0.0339, alpha = 0.105\n",
      "MNB: f1_score = 0.0045, alpha = 0.2\n",
      "MNB: f1_score = 0.0045, alpha = 0.3\n",
      "MNB: f1_score = 0.0, alpha = 0.4\n",
      "MNB: f1_score = 0.0, alpha = 0.5\n",
      "MNB: f1_score = 0.0, alpha = 0.6"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MNB: f1_score = 0.0, alpha = 0.7\n",
      "MNB: f1_score = 0.0, alpha = 1.0\n",
      "MNB: f1_score = 0.0, alpha = 10.0\n",
      "\n",
      "Multinomial Naive Bayes: optimal alpha = 0.0001\n",
      "\n",
      "------------------------\n",
      "Logistic Regression (LR)\n",
      "------------------------\n",
      "\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0, C = 0.01\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0, C = 0.1\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0045, C = 0.2\n",
      "-------------------------------\n",
      "-------------------------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR: f1_score = 0.0135, C = 0.3\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0178, C = 0.4\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0177, C = 0.5\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0177, C = 0.54\n",
      "-------------------------------\n",
      "-------------------------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR: f1_score = 0.0221, C = 0.55\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0221, C = 0.56\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "LR: f1_score = 0.022, C = 0.57\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "LR: f1_score = 0.022, C = 0.58\n",
      "-------------------------------\n",
      "-------------------------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR: f1_score = 0.0263, C = 0.59\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0306, C = 0.6\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0475, C = 0.7\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0641, C = 0.8\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0761, C = 0.9\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0795, C = 1.0\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "LR: f1_score = 0.0828, C = 1.1\n",
      "-------------------------------\n",
      "-------------------------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR: f1_score = 0.2324, C = 10\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "LR: f1_score = 0.2415, C = 20\n",
      "-------------------------------\n",
      "-------------------------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR: f1_score = 0.2541, C = 30\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "LR: f1_score = 0.2638, C = 40\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "LR: f1_score = 0.2701, C = 50\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "LR: f1_score = 0.2739, C = 100\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "LR: f1_score = 0.2755, C = 1000\n",
      "-------------------------------\n",
      "Logistic Regression: optimal C = 1000\n",
      "\n",
      "accuracy = 74.233490566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "# http://stackoverflow.com/questions/209840/map-two-lists-into-a-dictionary-in-python\n",
    "# http://stackoverflow.com/questions/268272/getting-key-with-maximum-value-in-dictionary\n",
    "\n",
    "# Notes\n",
    "# Classifier precision--when a positive value is predicted, proportion of time the prediction is correct--equals (TP) / (TP + FP)\n",
    "# Classifier recall--when the actual value is positive, the proportion of time the prediction is correct--equals (TP) / (TP + FN)\n",
    "\n",
    "train_data = train_data[\"request_text\"]\n",
    "dev_data = dev_data[\"request_text\"]\n",
    "\n",
    "def iterate():\n",
    "### STUDENT START ###\n",
    "\n",
    "    # create empty vector\n",
    "    accuracies = []\n",
    "\n",
    "    # Source: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "    # The F1 score can be interpreted as a weighted average of the precision and recall, \n",
    "    # where an F1 score reaches its best value at 1 and worst score at 0. \n",
    "    # The relative contribution of precision and recall to the F1 score are equal. \n",
    "    # The formula for the F1 score is: F1 = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(min_df=1, stop_words='english')\n",
    "    #vectorizer = CountVectorizer()\n",
    "    train_vectors = vectorizer.fit_transform(train_data)\n",
    "    print \"train_vectors.shape:\", train_vectors.shape\n",
    "    \n",
    "    dev_vectors = vectorizer.transform(dev_data)\n",
    "    print \"dev_vectors.shape:\", dev_vectors.shape\n",
    "    print\n",
    "    \n",
    "    #------------------------\n",
    "    # K Nearest Neighbors\n",
    "    #------------------------\n",
    "    \n",
    "    print \"------------------------------\"\n",
    "    print \"K Nearest Neighbors (K-NN)\"\n",
    "    print \"------------------------------\"\n",
    "    \n",
    "    # Euclidean distance, when you go to 10 to 20+ dimensions, too many examples can be close to each other\n",
    "    # With K-NN on text, Cosine or Manhattan distance might be better. Cosine distance measures the angle between examples,\n",
    "    # more robust for high-dimensional problems. \n",
    "    # Dot product measures length of vectors AND angle between these vectors. \n",
    "    # With Cosine distance, you can get a value 0 to 1.\n",
    "    \n",
    "    # create two vectors\n",
    "    # ks refers to a vector of k nearest neighbor values\n",
    "    \n",
    "    ks = [1, 5, 15, 16, 17, 18, 19, 20, 28, 29, 30, 31, 32, 150, 300]\n",
    "    f1_scores = []\n",
    "    \n",
    "    for k in ks:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, distance='cosine', algorithm='brute')\n",
    "        knn.fit(train_vectors, train_labels)\n",
    "        pred_1 = knn.predict(dev_vectors)\n",
    "        \n",
    "        # http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "        # f1_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)[source]¶\n",
    "            # y_true = Ground truth (correct) target values \n",
    "            # y_pred = Estimated targets as returned by a classifier.\n",
    "            # average = required for multiclass/multilabel targets.\n",
    "                # 'weighted': Calculate metrics for each label, and find their average, weighted by \n",
    "                # the number of true instances for each label. This alters ‘macro’ to account for label imbalance; \n",
    "                # it can result in an F-score that is not between precision and recall.\n",
    "            \n",
    "        print \"K-NN: f1_score = %s, k = %s\" % (round(metrics.f1_score(dev_labels, pred_1, average='binary'),4), k)\n",
    "\n",
    "        # append f1_scores to vector\n",
    "        f1_scores.append(metrics.f1_score(dev_labels, pred_1))\n",
    "    \n",
    "    print\n",
    "    \n",
    "    # map two vectors into a dictionary\n",
    "    results_knn = dict(zip(ks, f1_scores))\n",
    "    #print results_knn\n",
    "    \n",
    "    # print the key with the max fl_score\n",
    "    print \"K-NN: optimal k =\", max(results_knn.iteritems(), key=operator.itemgetter(1))[0]\n",
    "    print\n",
    "\n",
    "    #------------------------\n",
    "    # Multinomial Naive Bayes\n",
    "    #------------------------\n",
    "    \n",
    "    print \"-----------------------------\"\n",
    "    print \"Multinomial Naive Bayes (MNB)\"\n",
    "    print \"-----------------------------\"\n",
    "    \n",
    "    # create two vectors\n",
    "    \n",
    "    alphas = [0.0, 0.00001, 0.0001, 0.001, 0.01, 0.094, 0.095, 0.096, 0.1, 0.105, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 1.0, 10.0]\n",
    "    f1_scores = []\n",
    "    \n",
    "    for a in alphas:\n",
    "        mnb = MultinomialNB(alpha=a)\n",
    "        mnb.fit(train_vectors, train_labels)\n",
    "        pred_2 = mnb.predict(dev_vectors)\n",
    "        print \"MNB: f1_score = %s, alpha = %s\" % (round(metrics.f1_score(dev_labels, pred_2, average='binary'), 4), a)\n",
    "        \n",
    "        # append f1_scores to vector\n",
    "        f1_scores.append(metrics.f1_score(dev_labels, pred_2))\n",
    "        \n",
    "    print\n",
    "    \n",
    "    # map two vectors into a dictionary\n",
    "    results_mnb = dict(zip(alphas, f1_scores))\n",
    "    #print results_mnb\n",
    "    \n",
    "    # print the key with the max fl_score\n",
    "    print \"Multinomial Naive Bayes: optimal alpha =\", max(results_mnb.iteritems(), key=operator.itemgetter(1))[0]\n",
    "    print\n",
    "    \n",
    "    #------------------------\n",
    "    # Logistic Regression\n",
    "    #------------------------\n",
    "    \n",
    "    print \"------------------------\"\n",
    "    print \"Logistic Regression (LR)\"\n",
    "    print \"------------------------\"\n",
    "    print\n",
    "    \n",
    "    # create two vectors\n",
    "    # cs refers to the vector of C (inverse of regularization strength) values\n",
    "    \n",
    "    cs = [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, \\\n",
    "          10, 20, 30, 40, 50, 100, 1000]\n",
    "    f1_scores = []\n",
    "    \n",
    "    for c in cs:\n",
    "        \n",
    "        # logistic regression fits a line like linear regression, but instead of predicting any number, \n",
    "        # it predicts a number between 0 and 1 (sigmoid function).\n",
    "        \n",
    "        # http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "        # C (inverse of regularization strength) controls how much the weights influence the loss, and\n",
    "        # penalizes the sum of squared weights if very different weights exist between different tokens.\n",
    "  \n",
    "        # use l2 regularization, per instructions\n",
    "        lr = LogisticRegression(penalty='l2',C=c)\n",
    "        lr.fit(train_vectors, train_labels)\n",
    "        pred_3 = lr.predict(dev_vectors)\n",
    "        \n",
    "        print \"-------------------------------\"\n",
    "        print \"LR: f1_score = %s, C = %s\" % (round(metrics.f1_score(dev_labels, pred_3, average='binary'),4), c)\n",
    "        print \"-------------------------------\"\n",
    "        \n",
    "        # append f1_scores to vector\n",
    "        f1_scores.append(metrics.f1_score(dev_labels, pred_3, average='binary'))\n",
    "        \n",
    "        accuracies.append((lr.score(dev_vectors, dev_labels))*100) \n",
    "        \n",
    "        '''\n",
    "        # first define function that squares a given value, for later use in the 'for loop' below\n",
    "        fun_sq_wts = lambda x: x**2\n",
    "        \n",
    "        for label in range(0,4):\n",
    "         \n",
    "            # use map function, likely faster (because written in C) than list comprehension.\n",
    "            # map function itself applies a function, specifically the first argument on the second argument.\n",
    "            # from coef_, take raw weights (coefficient of the features in the decision function), \n",
    "            # and sum the squares of these weights.\n",
    "            \n",
    "            # note: averege=weight vs. average=default should be about same score if similar number of examples across classes\n",
    "            sq_wts = map(fun_sq_wts, lr.coef_[label])\n",
    "            sum_sq_wts = round(sum(sq_wts),2)\n",
    "            print \"Label = %s, sum of squared weights = %s\" % (label, sum_sq_wts)\n",
    "        \n",
    "        print\n",
    "        '''\n",
    "        \n",
    "    # map two vectors into a dictionary\n",
    "    results_lr = dict(zip(cs, f1_scores))\n",
    "    #print results_lr\n",
    "    \n",
    "    # print the key with the max fl_score\n",
    "    print \"Logistic Regression: optimal C =\", max(results_lr.iteritems(), key=operator.itemgetter(1))[0]\n",
    "    print\n",
    "    print \"accuracy =\", max(accuracies)\n",
    "        \n",
    "### STUDENT END ###\n",
    "\n",
    "iterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------\n",
      "unigram\n",
      "----------\n",
      "\n",
      "train_vectors.shape: (3975, 12313)\n",
      "\n",
      "[[-1.48092905 -0.39311615 -0.12825177 ...,  0.44453487  1.63180069\n",
      "  -0.87946286]]\n",
      "[3697, 4147, 6786, 8221, 1039, 6858, 3236, 1286, 6712, 10159, 1523, 10688, 4918, 10689, 9907, 7050, 3901, 2573, 2155, 9349]\n",
      "       Feature      word\n",
      "0         edit  4.824324\n",
      "1       father  4.627494\n",
      "2         mean  4.376547\n",
      "3      pockets  4.057164\n",
      "4          ass  3.995387\n",
      "5    mentioned  3.977975\n",
      "6          die  3.930683\n",
      "7        basic  3.899384\n",
      "8      married  3.850098\n",
      "9     southern -3.846223\n",
      "10       bloke  3.807984\n",
      "11    surprise  3.805289\n",
      "12   graveyard  3.749854\n",
      "13   surprised  3.697465\n",
      "14     sitting -3.697393\n",
      "15       mommy  3.658543\n",
      "16  especially  3.627059\n",
      "17  constantly  3.593246\n",
      "18      cheesy  3.548595\n",
      "19     running  3.539010\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "bigram\n",
      "----------\n",
      "\n",
      "train_vectors.shape: (3975, 90693)\n",
      "\n",
      "[[-0.31775435  0.42001296 -0.29407174 ..., -0.26401881 -0.22234693\n",
      "   0.57766744]]\n",
      "[23002, 38997, 37806, 32065, 28212, 73029, 33880, 44381, 54471, 23001, 81228, 41801, 77046, 2781, 47597, 9433, 84630, 16480, 57349, 59245]\n",
      "                Feature      word\n",
      "0           edit thanks  3.882043\n",
      "1             imgur com  3.879634\n",
      "2            http imgur  3.547851\n",
      "3             got pizza  3.038731\n",
      "4         forward money  2.984111\n",
      "5        sounds amazing  2.960338\n",
      "6        happy birthday  2.947813\n",
      "7   letsfytinglove best  2.947813\n",
      "8        north carolina  2.936326\n",
      "9            edit thank  2.927036\n",
      "10      tonight greatly  2.813269\n",
      "11           just spent  2.809594\n",
      "12         surprise son  2.768559\n",
      "13         afford ramen  2.674511\n",
      "14             love pie  2.633101\n",
      "15         broke payday  2.627687\n",
      "16               ve got  2.625031\n",
      "17        craving pizza -2.599092\n",
      "18          pay forward  2.518712\n",
      "19       pizza actually  2.512937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pandas import *\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Feature Selection Notes:\n",
    "'''\n",
    "http://scikit-learn.org/stable/datasets/twenty_newsgroups.html\n",
    "http://scikit-learn.org/stable/modules/feature_selection.html\n",
    "http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html#example-text-document-classification-20newsgroups-py\n",
    "\n",
    "These objects take as input a scoring function that returns univariate p-values:\n",
    "-For regression: f_regression\n",
    "-For classification: chi2 or f_classif\n",
    "\n",
    "Feature selection with sparse data:\n",
    "-If you use sparse data (i.e. data represented as sparse matrices), \n",
    "only chi2 will deal with the data without making it dense.\n",
    "-Warning: Beware not to use a regression scoring function with a classification problem, \n",
    "you will get useless results.\n",
    "\n",
    "With SVMs and logistic-regression, the parameter C controls the sparsity: \n",
    "the smaller C the less features selected. \n",
    "'''\n",
    "\n",
    "def top20(type):\n",
    "### STUDENT START ###\n",
    "\n",
    "    if type == \"unigram\":\n",
    "        \n",
    "        # use stop_words='english' to remove less meaningful words. \n",
    "        # only applies if default analyzer='word'.\n",
    "        vectorizer = TfidfVectorizer(min_df=1, stop_words='english')\n",
    "        #vectorizer = CountVectorizer(min_df=1, stop_words='english')\n",
    "        train_vectors = vectorizer.fit_transform(train_data)\n",
    "        print\n",
    "        print \"----------\"\n",
    "        print \"unigram\"\n",
    "        print \"----------\"\n",
    "        print\n",
    "        print \"train_vectors.shape:\", train_vectors.shape\n",
    "        print\n",
    "        \n",
    "    elif type == \"bigram\":\n",
    "        \n",
    "        # use stop_words='english' to remove less meaningful words from the resulting tokens. \n",
    "        # only applies if default analyzer='word'.\n",
    "        # set bigrams to be 2 words only\n",
    "        vectorizer = TfidfVectorizer(min_df=1, stop_words='english', ngram_range=(2, 2))\n",
    "        #vectorizer = CountVectorizer(min_df=1, stop_words='english', ngram_range=(2, 2))\n",
    "        train_vectors = vectorizer.fit_transform(train_data)\n",
    "        print\n",
    "        print \"----------\"\n",
    "        print \"bigram\"\n",
    "        print \"----------\"\n",
    "        print\n",
    "        print \"train_vectors.shape:\", train_vectors.shape\n",
    "        print\n",
    "      \n",
    "    # use C=12\n",
    "    for c in [12]:\n",
    "        \n",
    "        # in the multiclass case, the training algorithm uses the one-vs-rest (OvR) scheme if the default ‘multi_class’ option is set to ‘ovr’ \n",
    "        lr = LogisticRegression(penalty='l2',C=c)\n",
    "        #print lr\n",
    "        \n",
    "        # fit the model and generate coef_\n",
    "        lr.fit(train_vectors, train_labels)\n",
    "         \n",
    "        # interested in magnitude of the weights (coefficients), so take absolute value.\n",
    "        # sort absolute values in descending order.\n",
    "        # important to know if negative or positive weight, so still output the positive/negative sign.\n",
    "        # after fitting logistic regression for class vs. all other classes, negative weight of a token \n",
    "        # indicates a class other than class of interest.\n",
    "        # (visual example of negative and positive on a sigmoid function helps) \n",
    "        \n",
    "        print lr.coef_\n",
    "        \n",
    "        # for each label, store the column indices of the top 5 weights \n",
    "        top20 = sorted(range(len(lr.coef_[0])), key=lambda i: abs(lr.coef_[0][i]), reverse=True)[:20]\n",
    "       \n",
    "        col_1 = []\n",
    "        \n",
    "        # for each label, access and store weights via column indices\n",
    "        for index in (top20):\n",
    "\n",
    "            col_1.append(lr.coef_[0][index])\n",
    "           \n",
    "        print top20\n",
    "\n",
    "        # store feature names, after converting to an array\n",
    "        feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "       \n",
    "        # create a Pandas dataframe with 20 rows and 4 columns, plus descriptive headers\n",
    "        df = DataFrame({'Feature': feature_names[top20], 'word': col_1})\n",
    "        print df    \n",
    "\n",
    "    print\n",
    "\n",
    "#-----\n",
    "         \n",
    "### STUDENT END ###\n",
    "top20(\"unigram\")\n",
    "top20(\"bigram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "C =  0.01\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.0\n",
      "LR L2 regularization: f1_score = 0.0\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 0\n",
      "LR L2 regularization: number of non-zero weights = 12313\n",
      "\n",
      "LR L1 regularization: accuracy = 74.12%\n",
      "LR L2 regularization: accuracy = 74.12%\n",
      "\n",
      "\n",
      "-----------------\n",
      "C =  0.03\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.0\n",
      "LR L2 regularization: f1_score = 0.0\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 0\n",
      "LR L2 regularization: number of non-zero weights = 12313\n",
      "\n",
      "LR L1 regularization: accuracy = 74.12%\n",
      "LR L2 regularization: accuracy = 74.12%\n",
      "\n",
      "\n",
      "-----------------\n",
      "C =  0.05\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.0\n",
      "LR L2 regularization: f1_score = 0.0\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 0\n",
      "LR L2 regularization: number of non-zero weights = 12313\n",
      "\n",
      "LR L1 regularization: accuracy = 74.12%\n",
      "LR L2 regularization: accuracy = 74.12%\n",
      "\n",
      "\n",
      "-----------------\n",
      "C =  0.07\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.0\n",
      "LR L2 regularization: f1_score = 0.0\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 0\n",
      "LR L2 regularization: number of non-zero weights = 12313\n",
      "\n",
      "LR L1 regularization: accuracy = 74.12%\n",
      "LR L2 regularization: accuracy = 74.12%\n",
      "\n",
      "\n",
      "-----------------\n",
      "C =  0.1\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.0\n",
      "LR L2 regularization: f1_score = 0.0\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 0\n",
      "LR L2 regularization: number of non-zero weights = 12313\n",
      "\n",
      "LR L1 regularization: accuracy = 74.12%\n",
      "LR L2 regularization: accuracy = 74.12%\n",
      "\n",
      "\n",
      "-----------------\n",
      "C =  0.3\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.0089\n",
      "LR L2 regularization: f1_score = 0.0135\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 10\n",
      "LR L2 regularization: number of non-zero weights = 12313\n",
      "\n",
      "LR L1 regularization: accuracy = 73.82%\n",
      "LR L2 regularization: accuracy = 74.12%\n",
      "\n",
      "  (0, 8)\t0.128616157726\n",
      "  (0, 2)\t0.0703176456145\n",
      "  (0, 9)\t0.0684814651588\n",
      "  (0, 6)\t0.0769481275445\n",
      "  (1, 7)\t0.143631285742\n",
      "  (1, 0)\t0.0930310837977\n",
      "  (2, 8)\t0.151850942384\n",
      "  (2, 2)\t0.166041358124\n",
      "  (3, 0)\t0.0953133050736\n",
      "  (5, 8)\t0.0715073031098\n",
      "  (5, 0)\t0.0879789926127\n",
      "  (6, 8)\t0.103159349252\n",
      "  (6, 7)\t0.0979779056358\n",
      "  (6, 0)\t0.126922079719\n",
      "  (8, 6)\t0.341113578446\n",
      "  (9, 2)\t0.0680770326592\n",
      "  (10, 7)\t0.062724554707\n",
      "  (12, 7)\t0.118268545534\n",
      "  (12, 3)\t0.0946126864526\n",
      "  (13, 0)\t0.0547232043539\n",
      "  (15, 8)\t0.0922064880126\n",
      "  (15, 9)\t0.0981903908169\n",
      "  (16, 7)\t0.158966751294\n",
      "  (18, 8)\t0.122500245056\n",
      "  (19, 2)\t0.166371622169\n",
      "  :\t:\n",
      "  (3947, 7)\t0.109373544142\n",
      "  (3949, 6)\t0.10029005797\n",
      "  (3952, 7)\t0.067145207455\n",
      "  (3953, 2)\t0.0959156862658\n",
      "  (3953, 3)\t0.133297045893\n",
      "  (3957, 8)\t0.0894602529365\n",
      "  (3957, 2)\t0.097820281274\n",
      "  (3957, 3)\t0.135943921478\n",
      "  (3958, 9)\t0.10089357567\n",
      "  (3958, 7)\t0.0899861277529\n",
      "  (3959, 8)\t0.155112412082\n",
      "  (3959, 7)\t0.147321492275\n",
      "  (3961, 8)\t0.0572660051065\n",
      "  (3963, 8)\t0.0488627981577\n",
      "  (3963, 4)\t0.0678076068162\n",
      "  (3965, 8)\t0.0649491716679\n",
      "  (3965, 9)\t0.0691641628129\n",
      "  (3965, 7)\t0.030843466244\n",
      "  (3965, 4)\t0.0450654491918\n",
      "  (3966, 8)\t0.0780980246048\n",
      "  (3966, 2)\t0.085396256807\n",
      "  (3968, 8)\t0.1375960961\n",
      "  (3971, 6)\t0.0925187134682\n",
      "  (3973, 2)\t0.158636471288\n",
      "  (3973, 6)\t0.173594825584\n",
      "-----------------\n",
      "C =  0.5\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.0263\n",
      "LR L2 regularization: f1_score = 0.0177\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 37\n",
      "LR L2 regularization: number of non-zero weights = 12313\n",
      "\n",
      "LR L1 regularization: accuracy = 73.82%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR L2 regularization: accuracy = 73.88%\n",
      "\n",
      "  (0, 18)\t0.131488281208\n",
      "  (0, 33)\t0.128616157726\n",
      "  (0, 16)\t0.0703176456145\n",
      "  (0, 1)\t0.0854815153819\n",
      "  (0, 9)\t0.0592093216538\n",
      "  (0, 12)\t0.072392176734\n",
      "  (0, 36)\t0.0684814651588\n",
      "  (0, 29)\t0.0769481275445\n",
      "  (1, 18)\t0.0773020500597\n",
      "  (1, 12)\t0.0851188199955\n",
      "  (1, 23)\t0.105034099048\n",
      "  (1, 30)\t0.143631285742\n",
      "  (1, 8)\t0.0930310837977\n",
      "  (1, 6)\t0.0909178660832\n",
      "  (2, 33)\t0.151850942384\n",
      "  (2, 16)\t0.166041358124\n",
      "  (2, 32)\t0.261775215436\n",
      "  (2, 20)\t0.215739055306\n",
      "  (3, 18)\t0.0791984096001\n",
      "  (3, 8)\t0.0953133050736\n",
      "  (3, 34)\t0.0796062520293\n",
      "  (3, 19)\t0.084367646913\n",
      "  (5, 18)\t0.0731041305069\n",
      "  (5, 33)\t0.0715073031098\n",
      "  (5, 1)\t0.0950510843857\n",
      "  :\t:\n",
      "  (3965, 20)\t0.092275179321\n",
      "  (3965, 34)\t0.100112224021\n",
      "  (3965, 0)\t0.0426428230597\n",
      "  (3965, 7)\t0.0388307252242\n",
      "  (3965, 24)\t0.0450654491918\n",
      "  (3965, 31)\t0.0779315345366\n",
      "  (3965, 4)\t0.0990794605162\n",
      "  (3966, 33)\t0.0780980246048\n",
      "  (3966, 16)\t0.085396256807\n",
      "  (3966, 9)\t0.0719059119959\n",
      "  (3966, 20)\t0.110956137545\n",
      "  (3966, 34)\t0.0802531860333\n",
      "  (3967, 4)\t0.143207787989\n",
      "  (3968, 33)\t0.1375960961\n",
      "  (3968, 20)\t0.0977433900654\n",
      "  (3969, 9)\t0.200570721048\n",
      "  (3969, 7)\t0.130240144999\n",
      "  (3971, 12)\t0.087040858177\n",
      "  (3971, 29)\t0.0925187134682\n",
      "  (3971, 34)\t0.0794546462198\n",
      "  (3973, 16)\t0.158636471288\n",
      "  (3973, 29)\t0.173594825584\n",
      "  (3973, 34)\t0.14908243895\n",
      "  (3973, 14)\t0.175180934735\n",
      "  (3974, 14)\t0.267515250897\n",
      "-----------------\n",
      "C =  0.57\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.0306\n",
      "LR L2 regularization: f1_score = 0.0177\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 41\n",
      "LR L2 regularization: number of non-zero weights = 12313\n",
      "\n",
      "LR L1 regularization: accuracy = 73.88%\n",
      "LR L2 regularization: accuracy = 73.76%\n",
      "\n",
      "  (0, 22)\t0.131488281208\n",
      "  (0, 37)\t0.128616157726\n",
      "  (0, 20)\t0.0703176456145\n",
      "  (0, 1)\t0.0854815153819\n",
      "  (0, 10)\t0.0592093216538\n",
      "  (0, 14)\t0.072392176734\n",
      "  (0, 40)\t0.0684814651588\n",
      "  (0, 33)\t0.0769481275445\n",
      "  (1, 22)\t0.0773020500597\n",
      "  (1, 14)\t0.0851188199955\n",
      "  (1, 27)\t0.105034099048\n",
      "  (1, 34)\t0.143631285742\n",
      "  (1, 9)\t0.0930310837977\n",
      "  (1, 6)\t0.0909178660832\n",
      "  (2, 37)\t0.151850942384\n",
      "  (2, 20)\t0.166041358124\n",
      "  (2, 36)\t0.261775215436\n",
      "  (2, 24)\t0.215739055306\n",
      "  (3, 22)\t0.0791984096001\n",
      "  (3, 9)\t0.0953133050736\n",
      "  (3, 38)\t0.0796062520293\n",
      "  (3, 23)\t0.084367646913\n",
      "  (5, 22)\t0.0731041305069\n",
      "  (5, 37)\t0.0715073031098\n",
      "  (5, 1)\t0.0950510843857\n",
      "  :\t:\n",
      "  (3965, 38)\t0.100112224021\n",
      "  (3965, 0)\t0.0426428230597\n",
      "  (3965, 8)\t0.0388307252242\n",
      "  (3965, 28)\t0.0450654491918\n",
      "  (3965, 35)\t0.0779315345366\n",
      "  (3965, 4)\t0.0990794605162\n",
      "  (3966, 37)\t0.0780980246048\n",
      "  (3966, 20)\t0.085396256807\n",
      "  (3966, 10)\t0.0719059119959\n",
      "  (3966, 24)\t0.110956137545\n",
      "  (3966, 38)\t0.0802531860333\n",
      "  (3967, 13)\t0.160903428014\n",
      "  (3967, 4)\t0.143207787989\n",
      "  (3968, 37)\t0.1375960961\n",
      "  (3968, 24)\t0.0977433900654\n",
      "  (3969, 10)\t0.200570721048\n",
      "  (3969, 8)\t0.130240144999\n",
      "  (3971, 14)\t0.087040858177\n",
      "  (3971, 33)\t0.0925187134682\n",
      "  (3971, 38)\t0.0794546462198\n",
      "  (3973, 20)\t0.158636471288\n",
      "  (3973, 33)\t0.173594825584\n",
      "  (3973, 38)\t0.14908243895\n",
      "  (3973, 18)\t0.175180934735\n",
      "  (3974, 18)\t0.267515250897\n",
      "-----------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C =  0.7\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.043\n",
      "LR L2 regularization: f1_score = 0.0475\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 64\n",
      "LR L2 regularization: number of non-zero weights = 12313\n",
      "\n",
      "LR L1 regularization: accuracy = 73.76%\n",
      "LR L2 regularization: accuracy = 74.00%\n",
      "\n",
      "  (0, 29)\t0.131488281208\n",
      "  (0, 57)\t0.128616157726\n",
      "  (0, 62)\t0.0882030199794\n",
      "  (0, 27)\t0.0703176456145\n",
      "  (0, 35)\t0.0833097087161\n",
      "  (0, 1)\t0.0854815153819\n",
      "  (0, 14)\t0.0592093216538\n",
      "  (0, 20)\t0.072392176734\n",
      "  (0, 61)\t0.0684814651588\n",
      "  (0, 51)\t0.0769481275445\n",
      "  (1, 29)\t0.0773020500597\n",
      "  (1, 20)\t0.0851188199955\n",
      "  (1, 40)\t0.105034099048\n",
      "  (1, 63)\t0.128159558573\n",
      "  (1, 3)\t0.0875019879519\n",
      "  (1, 52)\t0.143631285742\n",
      "  (1, 32)\t0.086776955993\n",
      "  (1, 12)\t0.0930310837977\n",
      "  (1, 9)\t0.0909178660832\n",
      "  (2, 57)\t0.151850942384\n",
      "  (2, 27)\t0.166041358124\n",
      "  (2, 56)\t0.261775215436\n",
      "  (2, 36)\t0.215739055306\n",
      "  (3, 29)\t0.0791984096001\n",
      "  (3, 63)\t0.13130354507\n",
      "  :\t:\n",
      "  (3966, 36)\t0.110956137545\n",
      "  (3966, 58)\t0.0802531860333\n",
      "  (3966, 21)\t0.0650328788759\n",
      "  (3966, 13)\t0.168400540161\n",
      "  (3967, 60)\t0.262377258056\n",
      "  (3967, 19)\t0.160903428014\n",
      "  (3967, 5)\t0.143207787989\n",
      "  (3968, 57)\t0.1375960961\n",
      "  (3968, 32)\t0.0789552537475\n",
      "  (3968, 36)\t0.0977433900654\n",
      "  (3968, 21)\t0.114577421091\n",
      "  (3969, 14)\t0.200570721048\n",
      "  (3969, 11)\t0.130240144999\n",
      "  (3970, 37)\t0.17969081438\n",
      "  (3971, 20)\t0.087040858177\n",
      "  (3971, 51)\t0.0925187134682\n",
      "  (3971, 58)\t0.0794546462198\n",
      "  (3972, 30)\t0.1534511295\n",
      "  (3973, 27)\t0.158636471288\n",
      "  (3973, 51)\t0.173594825584\n",
      "  (3973, 58)\t0.14908243895\n",
      "  (3973, 25)\t0.175180934735\n",
      "  (3974, 3)\t0.256380144057\n",
      "  (3974, 25)\t0.267515250897\n",
      "  (3974, 18)\t0.327667447475\n",
      "-----------------\n",
      "C =  1.0\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.071\n",
      "LR L2 regularization: f1_score = 0.0833\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 130\n",
      "LR L2 regularization: number of non-zero weights = 12313\n",
      "\n",
      "LR L1 regularization: accuracy = 73.76%\n",
      "LR L2 regularization: accuracy = 74.06%\n",
      "\n",
      "  (0, 68)\t0.131488281208\n",
      "  (0, 122)\t0.128616157726\n",
      "  (0, 66)\t0.120502336384\n",
      "  (0, 128)\t0.0882030199794\n",
      "  (0, 62)\t0.0703176456145\n",
      "  (0, 77)\t0.0833097087161\n",
      "  (0, 1)\t0.0854815153819\n",
      "  (0, 85)\t0.0761613900474\n",
      "  (0, 94)\t0.174978636747\n",
      "  (0, 43)\t0.0592093216538\n",
      "  (0, 52)\t0.072392176734\n",
      "  (0, 12)\t0.136104563515\n",
      "  (0, 127)\t0.0684814651588\n",
      "  (0, 121)\t0.0902335484595\n",
      "  (0, 114)\t0.0769481275445\n",
      "  (0, 2)\t0.107267469526\n",
      "  (1, 68)\t0.0773020500597\n",
      "  (1, 52)\t0.0851188199955\n",
      "  (1, 12)\t0.320063862286\n",
      "  (1, 2)\t0.126125236757\n",
      "  (1, 87)\t0.105034099048\n",
      "  (1, 129)\t0.128159558573\n",
      "  (1, 10)\t0.0875019879519\n",
      "  (1, 30)\t0.107426339043\n",
      "  (1, 115)\t0.143631285742\n",
      "  :\t:\n",
      "  (3967, 7)\t0.229047481957\n",
      "  (3968, 122)\t0.1375960961\n",
      "  (3968, 74)\t0.0789552537475\n",
      "  (3968, 78)\t0.0977433900654\n",
      "  (3968, 55)\t0.114577421091\n",
      "  (3968, 71)\t0.0991207719597\n",
      "  (3969, 43)\t0.200570721048\n",
      "  (3969, 119)\t0.133325954699\n",
      "  (3969, 35)\t0.130240144999\n",
      "  (3970, 80)\t0.17969081438\n",
      "  (3971, 94)\t0.0701286215915\n",
      "  (3971, 52)\t0.087040858177\n",
      "  (3971, 114)\t0.0925187134682\n",
      "  (3971, 123)\t0.0794546462198\n",
      "  (3971, 57)\t0.154338157854\n",
      "  (3972, 67)\t0.162926480126\n",
      "  (3972, 69)\t0.1534511295\n",
      "  (3973, 62)\t0.158636471288\n",
      "  (3973, 94)\t0.394751463047\n",
      "  (3973, 114)\t0.173594825584\n",
      "  (3973, 123)\t0.14908243895\n",
      "  (3973, 60)\t0.175180934735\n",
      "  (3974, 10)\t0.256380144057\n",
      "  (3974, 60)\t0.267515250897\n",
      "  (3974, 48)\t0.327667447475\n",
      "-----------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C =  10.0\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.2674\n",
      "LR L2 regularization: f1_score = 0.2371\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 1794\n",
      "LR L2 regularization: number of non-zero weights = 12313\n",
      "\n",
      "LR L1 regularization: accuracy = 67.04%\n",
      "LR L2 regularization: accuracy = 70.40%\n",
      "\n",
      "  (0, 317)\t0.0864076489886\n",
      "  (0, 112)\t0.148521746893\n",
      "  (0, 924)\t0.131488281208\n",
      "  (0, 1692)\t0.128616157726\n",
      "  (0, 867)\t0.101201982341\n",
      "  (0, 897)\t0.120502336384\n",
      "  (0, 32)\t0.172363809879\n",
      "  (0, 1781)\t0.0882030199794\n",
      "  (0, 1101)\t0.0942274380032\n",
      "  (0, 1426)\t0.123566142645\n",
      "  (0, 719)\t0.113112789872\n",
      "  (0, 858)\t0.0703176456145\n",
      "  (0, 172)\t0.0924492814871\n",
      "  (0, 1586)\t0.102104460156\n",
      "  (0, 57)\t0.0854815153819\n",
      "  (0, 1074)\t0.120502336384\n",
      "  (0, 618)\t0.126248490588\n",
      "  (0, 569)\t0.159946626501\n",
      "  (0, 139)\t0.143097558545\n",
      "  (0, 1730)\t0.127495331414\n",
      "  (0, 73)\t0.144774641873\n",
      "  (0, 1139)\t0.0761613900474\n",
      "  (0, 1024)\t0.106899158437\n",
      "  (0, 1273)\t0.174978636747\n",
      "  (0, 1211)\t0.114075611446\n",
      "  :\t:\n",
      "  (3971, 74)\t0.192312101408\n",
      "  (3971, 20)\t0.210684349826\n",
      "  (3972, 905)\t0.162926480126\n",
      "  (3972, 1520)\t0.21358400377\n",
      "  (3972, 1771)\t0.255223194035\n",
      "  (3972, 931)\t0.1534511295\n",
      "  (3972, 895)\t0.294163964296\n",
      "  (3972, 804)\t0.328813659646\n",
      "  (3972, 1230)\t0.340467568291\n",
      "  (3973, 867)\t0.228311474675\n",
      "  (3973, 858)\t0.158636471288\n",
      "  (3973, 1273)\t0.394751463047\n",
      "  (3973, 1577)\t0.173594825584\n",
      "  (3973, 1191)\t0.0818182671295\n",
      "  (3973, 1599)\t0.154409227383\n",
      "  (3973, 1732)\t0.14908243895\n",
      "  (3973, 760)\t0.227382473155\n",
      "  (3973, 795)\t0.175180934735\n",
      "  (3973, 103)\t0.19458168659\n",
      "  (3973, 945)\t0.222477399853\n",
      "  (3974, 206)\t0.256380144057\n",
      "  (3974, 795)\t0.267515250897\n",
      "  (3974, 1068)\t0.285824838279\n",
      "  (3974, 632)\t0.327667447475\n",
      "  (3974, 196)\t0.433553045773\n",
      "-----------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C =  12.0\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.2753\n",
      "LR L2 regularization: f1_score = 0.2376\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 1851\n",
      "LR L2 regularization: number of non-zero weights = 12313\n",
      "\n",
      "LR L1 regularization: accuracy = 67.10%\n",
      "LR L2 regularization: accuracy = 70.11%\n",
      "\n",
      "  (0, 330)\t0.0864076489886\n",
      "  (0, 117)\t0.148521746893\n",
      "  (0, 958)\t0.131488281208\n",
      "  (0, 1751)\t0.128616157726\n",
      "  (0, 899)\t0.101201982341\n",
      "  (0, 931)\t0.120502336384\n",
      "  (0, 33)\t0.172363809879\n",
      "  (0, 1839)\t0.0882030199794\n",
      "  (0, 1144)\t0.0942274380032\n",
      "  (0, 1475)\t0.123566142645\n",
      "  (0, 744)\t0.113112789872\n",
      "  (0, 889)\t0.0703176456145\n",
      "  (0, 180)\t0.0924492814871\n",
      "  (0, 1642)\t0.102104460156\n",
      "  (0, 60)\t0.0854815153819\n",
      "  (0, 1116)\t0.120502336384\n",
      "  (0, 647)\t0.126248490588\n",
      "  (0, 596)\t0.159946626501\n",
      "  (0, 145)\t0.143097558545\n",
      "  (0, 1789)\t0.127495331414\n",
      "  (0, 76)\t0.144774641873\n",
      "  (0, 1184)\t0.0761613900474\n",
      "  (0, 1062)\t0.106899158437\n",
      "  (0, 623)\t0.127925573916\n",
      "  (0, 1324)\t0.174978636747\n",
      "  :\t:\n",
      "  (3972, 939)\t0.162926480126\n",
      "  (3972, 1573)\t0.21358400377\n",
      "  (3972, 1829)\t0.255223194035\n",
      "  (3972, 965)\t0.1534511295\n",
      "  (3972, 929)\t0.294163964296\n",
      "  (3972, 833)\t0.328813659646\n",
      "  (3972, 1279)\t0.340467568291\n",
      "  (3972, 442)\t0.36641797358\n",
      "  (3973, 899)\t0.228311474675\n",
      "  (3973, 889)\t0.158636471288\n",
      "  (3973, 1324)\t0.394751463047\n",
      "  (3973, 1633)\t0.173594825584\n",
      "  (3973, 1239)\t0.0818182671295\n",
      "  (3973, 1656)\t0.154409227383\n",
      "  (3973, 1064)\t0.13433494087\n",
      "  (3973, 1791)\t0.14908243895\n",
      "  (3973, 787)\t0.227382473155\n",
      "  (3973, 824)\t0.175180934735\n",
      "  (3973, 107)\t0.19458168659\n",
      "  (3973, 980)\t0.222477399853\n",
      "  (3974, 215)\t0.256380144057\n",
      "  (3974, 824)\t0.267515250897\n",
      "  (3974, 1109)\t0.285824838279\n",
      "  (3974, 660)\t0.327667447475\n",
      "  (3974, 206)\t0.433553045773\n",
      "-----------------\n",
      "C =  30.0\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.2783\n",
      "LR L2 regularization: f1_score = 0.2521\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 2242\n",
      "LR L2 regularization: number of non-zero weights = 12313\n",
      "\n",
      "LR L1 regularization: accuracy = 65.45%\n",
      "LR L2 regularization: accuracy = 68.16%\n",
      "\n",
      "  (0, 1860)\t0.106899158437\n",
      "  (0, 154)\t0.148521746893\n",
      "  (0, 1144)\t0.131488281208\n",
      "  (0, 2118)\t0.128616157726\n",
      "  (0, 1072)\t0.101201982341\n",
      "  (0, 1112)\t0.120502336384\n",
      "  (0, 38)\t0.172363809879\n",
      "  (0, 2226)\t0.0882030199794\n",
      "  (0, 1381)\t0.0942274380032\n",
      "  (0, 1782)\t0.123566142645\n",
      "  (0, 884)\t0.113112789872\n",
      "  (0, 1059)\t0.0703176456145\n",
      "  (0, 1631)\t0.0906046711917\n",
      "  (0, 232)\t0.0924492814871\n",
      "  (0, 1283)\t0.0833097087161\n",
      "  (0, 1984)\t0.102104460156\n",
      "  (0, 800)\t0.111514500995\n",
      "  (0, 77)\t0.0854815153819\n",
      "  (0, 1347)\t0.120502336384\n",
      "  (0, 771)\t0.126248490588\n",
      "  (0, 717)\t0.159946626501\n",
      "  (0, 1797)\t0.112645312642\n",
      "  (0, 188)\t0.143097558545\n",
      "  (0, 98)\t0.144774641873\n",
      "  (0, 1429)\t0.0761613900474\n",
      "  :\t:\n",
      "  (3972, 1123)\t0.162926480126\n",
      "  (3972, 1901)\t0.21358400377\n",
      "  (3972, 2211)\t0.255223194035\n",
      "  (3972, 1152)\t0.1534511295\n",
      "  (3972, 1111)\t0.294163964296\n",
      "  (3972, 989)\t0.328813659646\n",
      "  (3972, 1538)\t0.340467568291\n",
      "  (3972, 542)\t0.36641797358\n",
      "  (3973, 1072)\t0.228311474675\n",
      "  (3973, 1059)\t0.158636471288\n",
      "  (3973, 1797)\t0.254127605503\n",
      "  (3973, 1596)\t0.394751463047\n",
      "  (3973, 1491)\t0.0818182671295\n",
      "  (3973, 2000)\t0.154409227383\n",
      "  (3973, 1277)\t0.13433494087\n",
      "  (3973, 936)\t0.227382473155\n",
      "  (3973, 979)\t0.175180934735\n",
      "  (3973, 141)\t0.19458168659\n",
      "  (3973, 1171)\t0.222477399853\n",
      "  (3974, 276)\t0.256380144057\n",
      "  (3974, 979)\t0.267515250897\n",
      "  (3974, 787)\t0.327667447475\n",
      "  (3974, 265)\t0.433553045773\n",
      "  (3974, 995)\t0.348216389435\n",
      "  (3974, 605)\t0.603672196303\n",
      "-----------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C =  50.0\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.2815\n",
      "LR L2 regularization: f1_score = 0.2642\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 2517\n",
      "LR L2 regularization: number of non-zero weights = 12313\n",
      "\n",
      "LR L1 regularization: accuracy = 65.68%\n",
      "LR L2 regularization: accuracy = 67.81%\n",
      "\n",
      "  (0, 2085)\t0.106899158437\n",
      "  (0, 175)\t0.148521746893\n",
      "  (0, 1286)\t0.131488281208\n",
      "  (0, 2374)\t0.128616157726\n",
      "  (0, 1208)\t0.101201982341\n",
      "  (0, 1251)\t0.120502336384\n",
      "  (0, 40)\t0.172363809879\n",
      "  (0, 2500)\t0.0882030199794\n",
      "  (0, 1555)\t0.0942274380032\n",
      "  (0, 2003)\t0.123566142645\n",
      "  (0, 1001)\t0.113112789872\n",
      "  (0, 1192)\t0.0703176456145\n",
      "  (0, 1838)\t0.0906046711917\n",
      "  (0, 265)\t0.0924492814871\n",
      "  (0, 1439)\t0.0833097087161\n",
      "  (0, 2225)\t0.102104460156\n",
      "  (0, 914)\t0.111514500995\n",
      "  (0, 82)\t0.0854815153819\n",
      "  (0, 1513)\t0.120502336384\n",
      "  (0, 881)\t0.126248490588\n",
      "  (0, 1440)\t0.156904152464\n",
      "  (0, 820)\t0.159946626501\n",
      "  (0, 2021)\t0.112645312642\n",
      "  (0, 216)\t0.143097558545\n",
      "  (0, 104)\t0.144774641873\n",
      "  :\t:\n",
      "  (3972, 2484)\t0.255223194035\n",
      "  (3972, 1294)\t0.1534511295\n",
      "  (3972, 1250)\t0.294163964296\n",
      "  (3972, 1114)\t0.328813659646\n",
      "  (3972, 1732)\t0.340467568291\n",
      "  (3972, 625)\t0.36641797358\n",
      "  (3973, 1208)\t0.228311474675\n",
      "  (3973, 1192)\t0.158636471288\n",
      "  (3973, 2021)\t0.254127605503\n",
      "  (3973, 1797)\t0.394751463047\n",
      "  (3973, 2211)\t0.173594825584\n",
      "  (3973, 1680)\t0.0818182671295\n",
      "  (3973, 2240)\t0.154409227383\n",
      "  (3973, 1433)\t0.13433494087\n",
      "  (3973, 1054)\t0.227382473155\n",
      "  (3973, 1102)\t0.175180934735\n",
      "  (3973, 161)\t0.19458168659\n",
      "  (3973, 1317)\t0.222477399853\n",
      "  (3974, 316)\t0.256380144057\n",
      "  (3974, 1102)\t0.267515250897\n",
      "  (3974, 1502)\t0.285824838279\n",
      "  (3974, 901)\t0.327667447475\n",
      "  (3974, 300)\t0.433553045773\n",
      "  (3974, 1121)\t0.348216389435\n",
      "  (3974, 694)\t0.603672196303\n",
      "-----------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C =  70.0\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.2885\n",
      "LR L2 regularization: f1_score = 0.2703\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 2673\n",
      "LR L2 regularization: number of non-zero weights = 12313\n",
      "\n",
      "LR L1 regularization: accuracy = 65.98%\n",
      "LR L2 regularization: accuracy = 67.22%\n",
      "\n",
      "  (0, 509)\t0.0864076489886\n",
      "  (0, 2217)\t0.106899158437\n",
      "  (0, 188)\t0.148521746893\n",
      "  (0, 1363)\t0.131488281208\n",
      "  (0, 2523)\t0.128616157726\n",
      "  (0, 1277)\t0.101201982341\n",
      "  (0, 1326)\t0.120502336384\n",
      "  (0, 48)\t0.172363809879\n",
      "  (0, 2653)\t0.0882030199794\n",
      "  (0, 1646)\t0.0942274380032\n",
      "  (0, 2126)\t0.123566142645\n",
      "  (0, 1066)\t0.113112789872\n",
      "  (0, 1260)\t0.0703176456145\n",
      "  (0, 1954)\t0.0906046711917\n",
      "  (0, 285)\t0.0924492814871\n",
      "  (0, 1526)\t0.0833097087161\n",
      "  (0, 2367)\t0.102104460156\n",
      "  (0, 973)\t0.111514500995\n",
      "  (0, 92)\t0.0854815153819\n",
      "  (0, 1605)\t0.120502336384\n",
      "  (0, 936)\t0.126248490588\n",
      "  (0, 1527)\t0.156904152464\n",
      "  (0, 871)\t0.159946626501\n",
      "  (0, 2147)\t0.112645312642\n",
      "  (0, 235)\t0.143097558545\n",
      "  :\t:\n",
      "  (3972, 1373)\t0.1534511295\n",
      "  (3972, 1325)\t0.294163964296\n",
      "  (3972, 1181)\t0.328813659646\n",
      "  (3972, 1841)\t0.340467568291\n",
      "  (3972, 729)\t0.323927900271\n",
      "  (3972, 667)\t0.36641797358\n",
      "  (3973, 1277)\t0.228311474675\n",
      "  (3973, 1260)\t0.158636471288\n",
      "  (3973, 2147)\t0.254127605503\n",
      "  (3973, 1912)\t0.394751463047\n",
      "  (3973, 2352)\t0.173594825584\n",
      "  (3973, 1782)\t0.0818182671295\n",
      "  (3973, 2383)\t0.154409227383\n",
      "  (3973, 1519)\t0.13433494087\n",
      "  (3973, 1122)\t0.227382473155\n",
      "  (3973, 1170)\t0.175180934735\n",
      "  (3973, 174)\t0.19458168659\n",
      "  (3973, 1398)\t0.222477399853\n",
      "  (3974, 338)\t0.256380144057\n",
      "  (3974, 1170)\t0.267515250897\n",
      "  (3974, 1593)\t0.285824838279\n",
      "  (3974, 958)\t0.327667447475\n",
      "  (3974, 321)\t0.433553045773\n",
      "  (3974, 1188)\t0.348216389435\n",
      "  (3974, 737)\t0.603672196303\n",
      "-----------------\n",
      "C =  100.0\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.2677\n",
      "LR L2 regularization: f1_score = 0.2737\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 3417\n",
      "LR L2 regularization: number of non-zero weights = 12313\n",
      "\n",
      "LR L1 regularization: accuracy = 65.80%\n",
      "LR L2 regularization: accuracy = 67.45%\n",
      "\n",
      "  (0, 653)\t0.0864076489886\n",
      "  (0, 2861)\t0.106899158437\n",
      "  (0, 255)\t0.148521746893\n",
      "  (0, 1733)\t0.131488281208\n",
      "  (0, 3224)\t0.128616157726\n",
      "  (0, 1629)\t0.101201982341\n",
      "  (0, 1690)\t0.120502336384\n",
      "  (0, 60)\t0.172363809879\n",
      "  (0, 3388)\t0.0882030199794\n",
      "  (0, 2101)\t0.0942274380032\n",
      "  (0, 2748)\t0.123566142645\n",
      "  (0, 1366)\t0.113112789872\n",
      "  (0, 1611)\t0.0703176456145\n",
      "  (0, 2511)\t0.0906046711917\n",
      "  (0, 372)\t0.0924492814871\n",
      "  (0, 1945)\t0.0833097087161\n",
      "  (0, 3047)\t0.102104460156\n",
      "  (0, 1243)\t0.111514500995\n",
      "  (0, 126)\t0.0854815153819\n",
      "  (0, 2045)\t0.120502336384\n",
      "  (0, 1200)\t0.126248490588\n",
      "  (0, 1946)\t0.156904152464\n",
      "  (0, 1116)\t0.159946626501\n",
      "  (0, 2773)\t0.112645312642\n",
      "  (0, 313)\t0.143097558545\n",
      "  :\t:\n",
      "  (3972, 1511)\t0.328813659646\n",
      "  (3972, 2350)\t0.340467568291\n",
      "  (3972, 940)\t0.323927900271\n",
      "  (3972, 863)\t0.36641797358\n",
      "  (3973, 1629)\t0.228311474675\n",
      "  (3973, 1611)\t0.158636471288\n",
      "  (3973, 2773)\t0.254127605503\n",
      "  (3973, 2448)\t0.394751463047\n",
      "  (3973, 3026)\t0.173594825584\n",
      "  (3973, 2275)\t0.0818182671295\n",
      "  (3973, 3067)\t0.154409227383\n",
      "  (3973, 1937)\t0.13433494087\n",
      "  (3973, 3288)\t0.14908243895\n",
      "  (3973, 1436)\t0.227382473155\n",
      "  (3973, 1496)\t0.175180934735\n",
      "  (3973, 238)\t0.19458168659\n",
      "  (3973, 1779)\t0.222477399853\n",
      "  (3973, 1215)\t0.373076235595\n",
      "  (3974, 443)\t0.256380144057\n",
      "  (3974, 1496)\t0.267515250897\n",
      "  (3974, 2031)\t0.285824838279\n",
      "  (3974, 1225)\t0.327667447475\n",
      "  (3974, 419)\t0.433553045773\n",
      "  (3974, 1518)\t0.348216389435\n",
      "  (3974, 950)\t0.603672196303\n",
      "-----------------\n",
      "C =  200.0\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.2646\n",
      "LR L2 regularization: f1_score = 0.2754\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 4035\n",
      "LR L2 regularization: number of non-zero weights = 12313\n",
      "\n",
      "LR L1 regularization: accuracy = 65.92%\n",
      "LR L2 regularization: accuracy = 66.80%\n",
      "\n",
      "  (0, 762)\t0.0864076489886\n",
      "  (0, 3374)\t0.106899158437\n",
      "  (0, 290)\t0.148521746893\n",
      "  (0, 2054)\t0.131488281208\n",
      "  (0, 3809)\t0.128616157726\n",
      "  (0, 1928)\t0.101201982341\n",
      "  (0, 449)\t0.0949991874822\n",
      "  (0, 2001)\t0.120502336384\n",
      "  (0, 74)\t0.172363809879\n",
      "  (0, 3999)\t0.0882030199794\n",
      "  (0, 2481)\t0.0942274380032\n",
      "  (0, 3234)\t0.123566142645\n",
      "  (0, 1616)\t0.113112789872\n",
      "  (0, 1906)\t0.0703176456145\n",
      "  (0, 2958)\t0.0906046711917\n",
      "  (0, 441)\t0.0924492814871\n",
      "  (0, 2299)\t0.0833097087161\n",
      "  (0, 3596)\t0.102104460156\n",
      "  (0, 1475)\t0.111514500995\n",
      "  (0, 145)\t0.0854815153819\n",
      "  (0, 3168)\t0.139350453525\n",
      "  (0, 2418)\t0.120502336384\n",
      "  (0, 1420)\t0.126248490588\n",
      "  (0, 2300)\t0.156904152464\n",
      "  (0, 1323)\t0.159946626501\n",
      "  :\t:\n",
      "  (3972, 1784)\t0.328813659646\n",
      "  (3972, 2759)\t0.340467568291\n",
      "  (3972, 1121)\t0.323927900271\n",
      "  (3972, 1032)\t0.36641797358\n",
      "  (3973, 1928)\t0.228311474675\n",
      "  (3973, 1906)\t0.158636471288\n",
      "  (3973, 3266)\t0.254127605503\n",
      "  (3973, 2885)\t0.394751463047\n",
      "  (3973, 3574)\t0.173594825584\n",
      "  (3973, 2674)\t0.0818182671295\n",
      "  (3973, 3617)\t0.154409227383\n",
      "  (3973, 2290)\t0.13433494087\n",
      "  (3973, 3890)\t0.14908243895\n",
      "  (3973, 1697)\t0.227382473155\n",
      "  (3973, 1763)\t0.175180934735\n",
      "  (3973, 271)\t0.19458168659\n",
      "  (3973, 2106)\t0.222477399853\n",
      "  (3973, 1435)\t0.373076235595\n",
      "  (3974, 531)\t0.256380144057\n",
      "  (3974, 1763)\t0.267515250897\n",
      "  (3974, 2399)\t0.285824838279\n",
      "  (3974, 1449)\t0.327667447475\n",
      "  (3974, 498)\t0.433553045773\n",
      "  (3974, 1792)\t0.348216389435\n",
      "  (3974, 1132)\t0.603672196303"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------\n",
      "C =  300.0\n",
      "-----------------\n",
      "LR L1 regularization: f1_score = 0.2459\n",
      "LR L2 regularization: f1_score = 0.2727\n",
      "\n",
      "LR L1 regularization: number of non-zero weights = 4471\n",
      "LR L2 regularization: number of non-zero weights = 12313\n",
      "\n",
      "LR L1 regularization: accuracy = 64.56%\n",
      "LR L2 regularization: accuracy = 66.04%\n",
      "\n",
      "  (0, 853)\t0.0864076489886\n",
      "  (0, 3755)\t0.106899158437\n",
      "  (0, 328)\t0.148521746893\n",
      "  (0, 2292)\t0.131488281208\n",
      "  (0, 4228)\t0.128616157726\n",
      "  (0, 2154)\t0.101201982341\n",
      "  (0, 2235)\t0.120502336384\n",
      "  (0, 78)\t0.172363809879\n",
      "  (0, 4434)\t0.0882030199794\n",
      "  (0, 2766)\t0.0942274380032\n",
      "  (0, 3604)\t0.123566142645\n",
      "  (0, 1784)\t0.113112789872\n",
      "  (0, 2129)\t0.0703176456145\n",
      "  (0, 492)\t0.0924492814871\n",
      "  (0, 2188)\t0.192075955732\n",
      "  (0, 2563)\t0.0833097087161\n",
      "  (0, 3992)\t0.102104460156\n",
      "  (0, 1631)\t0.111514500995\n",
      "  (0, 158)\t0.0854815153819\n",
      "  (0, 3532)\t0.139350453525\n",
      "  (0, 2700)\t0.120502336384\n",
      "  (0, 1577)\t0.126248490588\n",
      "  (0, 2564)\t0.156904152464\n",
      "  (0, 1481)\t0.159946626501\n",
      "  (0, 3637)\t0.112645312642\n",
      "  :\t:\n",
      "  (3972, 1980)\t0.328813659646\n",
      "  (3972, 3074)\t0.340467568291\n",
      "  (3972, 1250)\t0.323927900271\n",
      "  (3973, 2154)\t0.228311474675\n",
      "  (3973, 2129)\t0.158636471288\n",
      "  (3973, 3637)\t0.254127605503\n",
      "  (3973, 3217)\t0.394751463047\n",
      "  (3973, 3967)\t0.173594825584\n",
      "  (3973, 2981)\t0.0818182671295\n",
      "  (3973, 4016)\t0.154409227383\n",
      "  (3973, 2553)\t0.13433494087\n",
      "  (3973, 4314)\t0.14908243895\n",
      "  (3973, 1873)\t0.227382473155\n",
      "  (3973, 1956)\t0.175180934735\n",
      "  (3973, 3168)\t0.265074176031\n",
      "  (3973, 303)\t0.19458168659\n",
      "  (3973, 2354)\t0.222477399853\n",
      "  (3973, 1593)\t0.373076235595\n",
      "  (3974, 593)\t0.256380144057\n",
      "  (3974, 1956)\t0.267515250897\n",
      "  (3974, 2681)\t0.285824838279\n",
      "  (3974, 1606)\t0.327667447475\n",
      "  (3974, 555)\t0.433553045773\n",
      "  (3974, 1991)\t0.348216389435\n",
      "  (3974, 1262)\t0.603672196303\n"
     ]
    }
   ],
   "source": [
    "# http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.as_matrix.html\n",
    "# transform from pandas dataframe to numpy array\n",
    "train_data_np = train_data.as_matrix(columns=None)\n",
    "dev_data_np = dev_data.as_matrix(columns=None)\n",
    "\n",
    "train_labels_np = train_labels.as_matrix(columns=None)\n",
    "dev_labels_np = dev_labels.as_matrix(columns=None)\n",
    "\n",
    "#train_labels_np = np.ravel(train_labels_np)\n",
    "#dev_labels_np = np.ravel(dev_labels_np)\n",
    "\n",
    "# define function fs (feature selection)\n",
    "def fs():\n",
    "    # Keep this random seed here to make comparison easier.\n",
    "    \n",
    "    # create two empty vectors\n",
    "    accuracies = []\n",
    "    vocab_size = []\n",
    "    \n",
    "    ### STUDENT START ###\n",
    "\n",
    "    ### Logistic regression seeks the set of weights that minimizes errors in the training data AND has a small size.\n",
    "    ### For this size, the default regularization, L2, computes the sum of the squared weights (see P3, above), while \n",
    "    ### L1 regularization computes the sum of the absolute values of the weights. \n",
    "    ### L2 regularization makes all the weights relatively small, whereas\n",
    "    ### L1 regularization drives lots of the weights to 0, effectively removing unimportant features [for feature selection].\n",
    "\n",
    "    ### http://scikit-learn.org/stable/auto_examples/linear_model/plot_logistic_l1_l2_sparsity.html\n",
    "     \n",
    "    # set min_df=10 to ignore words that appear in less than 10 documents\n",
    "    # use stop_words='english' to remove less meaningful words from the resulting tokens, only applies if default analyzer='word'.\n",
    "\n",
    "    vectorizer = TfidfVectorizer(min_df=1, stop_words='english')\n",
    "    #vectorizer = CountVectorizer(min_df=1, stop_words='english')\n",
    "    train_vectors = vectorizer.fit_transform(train_data_np)\n",
    "    dev_vectors = vectorizer.transform(dev_data_np)    \n",
    "    \n",
    "    cs = [0.01, 0.03, 0.05, 0.07, 0.1, 0.3, 0.5, 0.57, 0.7, 1, 10, 12, 30, 50, 70, 100, 200, 300]\n",
    "    # no longer use np.linspace to return evenly spaced numbers over a specified interval.\n",
    "    # it offers less control.\n",
    "    \n",
    "    for c in cs:\n",
    "\n",
    "        # fit l1 and l2 models\n",
    "        lr_l1 = LogisticRegression(C=c, penalty='l1', tol=0.01)\n",
    "        lr_l2 = LogisticRegression(C=c, penalty='l2', tol=0.01)\n",
    "        lr_l1.fit(train_vectors, train_labels)\n",
    "        lr_l2.fit(train_vectors, train_labels)\n",
    "        \n",
    "        # store predictions\n",
    "        pred_l1 = lr_l1.predict(dev_vectors)\n",
    "        pred_l2 = lr_l2.predict(dev_vectors)\n",
    "        \n",
    "        print \"-----------------\"\n",
    "        print \"C = \", round(c,3)\n",
    "        print \"-----------------\"\n",
    "        \n",
    "        print \"LR L1 regularization: f1_score = %s\" % (round(metrics.f1_score(dev_labels, pred_l1, average='binary'),4))\n",
    "        print \"LR L2 regularization: f1_score = %s\" % (round(metrics.f1_score(dev_labels, pred_l2, average='binary'),4))\n",
    "        print\n",
    "        \n",
    "        #print \"lr_l1.coef_:\", lr_l1.coef_\n",
    "        #print \"lr_l2.coef_:\", lr_l2.coef_\n",
    "        \n",
    "        # take mean weight for each class\n",
    "        # axis=0 refers to mean of each column across 4 rows in coef_\n",
    "        # use as definition of sparsity\n",
    "        vec1 = np.mean(lr_l1.coef_, axis=0)\n",
    "        vec2 = np.mean(lr_l2.coef_, axis=0)\n",
    "        \n",
    "        #print \"vec1:\", vec1\n",
    "        #print \"vec2:\", vec2\n",
    "        \n",
    "        print \"LR L1 regularization: number of non-zero weights =\", (vec1 != 0).sum()\n",
    "        print \"LR L2 regularization: number of non-zero weights =\", (vec2 != 0).sum()\n",
    "        print \n",
    "        \n",
    "        # http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.score\n",
    "        # score(X, y, sample_weight=None)\n",
    "        # Returns the mean accuracy on the given dev or test data and labels\n",
    "        # In multi-label classification, this is the subset accuracy which is a harsh metric \n",
    "        # since you require for each sample that each label set be correctly predicted.\n",
    "        \n",
    "        print \"LR L1 regularization: accuracy = %.2f%%\" % ((lr_l1.score(dev_vectors, dev_labels))*100)\n",
    "        print \"LR L2 regularization: accuracy = %.2f%%\" % ((lr_l2.score(dev_vectors, dev_labels))*100)\n",
    "        print\n",
    "        \n",
    "        #print \"recheck\", train_vectors.shape\n",
    "        #print \"recheck\", train_labels.shape\n",
    "        \n",
    "        #---------------\n",
    "        # re-train model\n",
    "        #---------------\n",
    "        \n",
    "        # likely no need to use fit_transform again, as we still have our vocabulary in matrix format with token counts.\n",
    "        # we simply select non-zero weighted features (from columns), and leave documents (from rows) as is.\n",
    "        \n",
    "        # first, only select features that have non-zero weights from L1 regularization.\n",
    "        # vec1 includes weights for each feature (column).\n",
    "        train_vectors_rt = train_vectors[:, vec1 != 0]\n",
    "        dev_vectors_rt = dev_vectors[:, vec1 != 0]\n",
    "        \n",
    "        print train_vectors_rt\n",
    "        \n",
    "        #print \"recheck\", train_vectors_rt.shape\n",
    "        #print \"recheck\", train_labels.shape\n",
    "        \n",
    "        #############\n",
    "        # ERROR below due to 0 features\n",
    "        #############\n",
    "        \n",
    "        '''\n",
    "        lr_l2_rt = LogisticRegression(C=c, penalty='l2', tol=0.1)\n",
    "    \n",
    "        # refit our classifier to the model, so it can learn from the model\n",
    "        lr_l2_rt.fit(train_vectors_rt, train_labels)\n",
    "        pred_l2_rt = lr_l2_rt.predict(dev_vectors_rt)\n",
    "        \n",
    "        # take mean weight for each class\n",
    "        # axis=0 refers to mean of each column across 4 rows in coef_\n",
    "        # use as definition of sparsity\n",
    "        vec_rt = np.mean(lr_l2_rt.coef_, axis=0)\n",
    "        \n",
    "        # append to vectors\n",
    "        # note: try .score method (mean accuracy on the given test data and labels) rather than f1_score method,\n",
    "        #        partly because sometimes the output cell shows a system automated warning about the f1_score\n",
    "        accuracies.append((lr_l2_rt.score(dev_vectors_rt, dev_labels))*100)  \n",
    "        vocab_size.append(train_vectors_rt.shape[1])\n",
    "        \n",
    "        print \"***Re-trained model w/ L1 non-zero features***\" \n",
    "        print \"LR L2 regularization: f1_score = %s\" % (round(metrics.f1_score(dev_labels, pred_l2_rt, average='binary'),4))\n",
    "        print \"LR L2 regularization: number of non-zero weights:\", (vec_rt != 0).sum()\n",
    "        print \"LR L2 regularization: accuracy = %.2f%%\" % ((lr_l2_rt.score(dev_vectors_rt, dev_labels))*100)\n",
    "        print\n",
    "        print \"LR L2 regularization: vocab size:\", (train_vectors_rt.shape[1])\n",
    "        print\n",
    "    \n",
    "    #print accuracies\n",
    "    #print vocab_size\n",
    "    #print\n",
    "    \n",
    "    plt.scatter(vocab_size, accuracies)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Vocabulary Size')\n",
    "    plt.title('Relationship between Accuracy and Vocabulary Size')\n",
    "    '''\n",
    "    ### STUDENT END ###\n",
    "fs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 12313\n",
      "\n",
      "[[ 0.21100575  0.78899425]\n",
      " [ 0.99503696  0.00496304]\n",
      " [ 0.93736369  0.06263631]\n",
      " ..., \n",
      " [ 0.98865797  0.01134203]\n",
      " [ 0.48297265  0.51702735]\n",
      " [ 0.18677316  0.81322684]]\n",
      "\n",
      "(1696, 12313)\n",
      "[array([[ 1.        ],\n",
      "       [ 1.        ],\n",
      "       [ 1.        ],\n",
      "       ..., \n",
      "       [ 3.73920741],\n",
      "       [ 3.73920741],\n",
      "       [ 3.73920741]]), array([[ 200.48957473],\n",
      "       [ 200.48957473],\n",
      "       [ 200.48957473],\n",
      "       ..., \n",
      "       [   1.        ],\n",
      "       [   1.        ],\n",
      "       [   1.        ]]), array([[ 14.96518094],\n",
      "       [ 14.96518094],\n",
      "       [ 14.96518094],\n",
      "       ..., \n",
      "       [  1.        ],\n",
      "       [  1.        ],\n",
      "       [  1.        ]]), array([[ 23.72653157],\n",
      "       [ 23.72653157],\n",
      "       [ 23.72653157],\n",
      "       ..., \n",
      "       [  1.        ],\n",
      "       [  1.        ],\n",
      "       [  1.        ]]), array([[ 241.09908341],\n",
      "       [ 241.09908341],\n",
      "       [ 241.09908341],\n",
      "       ..., \n",
      "       [   1.        ],\n",
      "       [   1.        ],\n",
      "       [   1.        ]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dschan/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:63: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n"
     ]
    }
   ],
   "source": [
    "def fs2():\n",
    "    \n",
    "    ### STUDENT START ###\n",
    "    \n",
    "    # CountVectorizer:\n",
    "    # Tokenize the documents and count the occurrences of token and return them as a sparse matrix\n",
    "\n",
    "    # TfidfTransformer:\n",
    "    # Apply Term Frequency Inverse Document Frequency normalization to a sparse matrix of occurrence counts\n",
    "    \n",
    "    # Tf means term-frequency while tf-idf means term-frequency times inverse document-frequency\n",
    "    # This is a common term weighting scheme in information retrieval, \n",
    "    # that has also found good use in document classification.\n",
    "    # The goal of using tf-idf instead of the raw frequencies of occurrence of a token in a given document is to \n",
    "    # scale down the impact of tokens that occur very frequently in a given corpus and that are hence empirically \n",
    "    # less informative than features that occur in a small fraction of the training corpus.\n",
    "\n",
    "    vectorizer = TfidfVectorizer(min_df=1, stop_words='english')\n",
    "    \n",
    "    # apply the CountVectorizer fit_transform method -- which includes two methods in one -- on the train_data.\n",
    "    # learn the vocabulary dictionary (all tokens from the raw documents) and return a matrix, \n",
    "    # extracting token counts to the cells.\n",
    "    train_vectors = vectorizer.fit_transform(train_data)\n",
    "    \n",
    "    # apply the transform method to the dev_data\n",
    "    dev_vectors = vectorizer.transform(dev_data)\n",
    "    \n",
    "    # transform train_data to matrix and print count of rows and columns\n",
    "    # 2034 documents, 3064 words\n",
    "    print \"vocabulary size:\", train_vectors.toarray().shape[1] \n",
    "    print\n",
    "    \n",
    "    lr = LogisticRegression(penalty='l2', C=100)\n",
    "    lr.fit(train_vectors, train_labels)\n",
    "    pred_4 = lr.predict(dev_vectors)\n",
    "\n",
    "    # for each documents, store and print predicted probabilities that it belongs to each class\n",
    "    \n",
    "    # use the method, predict_proba\n",
    "    \n",
    "    '''\n",
    "    Probability estimates.\n",
    "    The returned estimates for all classes are ordered by the label of classes.\n",
    "    For a multi_class problem, if multi_class is set to be “multinomial” the softmax function is used to find the predicted probability of each class. \n",
    "    Else use a one-vs-rest approach, i.e., calculate the probability of each class assuming it to be positive using the logistic function \n",
    "    and normalize these values across all the classes.\n",
    "    '''\n",
    "    \n",
    "    # for each document in dev_vectors, get their probability estimates for all classes \n",
    "    p = lr.predict_proba(dev_vectors)\n",
    "    print p\n",
    "\n",
    "    # create an empty vector\n",
    "    \n",
    "    p_max_rates = []\n",
    "    R_rates = []\n",
    "    \n",
    "    # iterate over each row (document) of p\n",
    "    for i, p_docs in enumerate(p):\n",
    "        # p_docs is a 1x2 vector from p with a document's probability to each class on one row\n",
    "        # take the document's probability of the correct label\n",
    "        # dev_labels[10] will give dev_label of document 9\n",
    "        p_correct_class = p_docs[dev_labels]\n",
    "        # take the document's max probability across the 4 labels\n",
    "        p_max = p_docs.max()\n",
    "\n",
    "        p_max_rates.append(p_max)\n",
    "        \n",
    "        # calculate R\n",
    "        R = p_max / p_correct_class\n",
    "\n",
    "        # append to the R_rates vector\n",
    "        R_rates.append(R)\n",
    "\n",
    "    # create vector that have indices of top 3 R_rates\n",
    "    \n",
    "    #############\n",
    "    # ERROR below due to shape of vectors\n",
    "    #############\n",
    "    \n",
    "    print\n",
    "    print dev_vectors.shape\n",
    "    print R_rates[:5]\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    #print sorted(range(dev_vectors.shape[0]), key=lambda i: R_rates[i], reverse=True)\n",
    "            \n",
    "    #print \"dev indices of top 3 R_rates:\", top3_index\n",
    "    print\n",
    "    print \"dev labels\"\n",
    "    print \"0: 'alt.atheism', 1: 'comp.graphics', 2: 'sci.space', 3: 'talk.religion.misc'\"\n",
    "    print\n",
    "    for i in top3_index:\n",
    "        \n",
    "        # find index (0, 1, 2, or 3) of max probability within each row\n",
    "        # np.argmax returns the indices of the maximum values along an axis\n",
    "        index_max_prob = np.argmax(p[i,:])\n",
    "                                   \n",
    "        print \"---------------------------------------------------------------------\"\n",
    "        print \"W207 Results\"\n",
    "        print \"------------\"\n",
    "        print \"R_rate:\", R_rates[i]\n",
    "        print \"label probabilities:\", p[i,:]\n",
    "        print \"Max probability dev_label -> %s: %s\" % (index_max_prob, dev_labels[index_max_prob])\n",
    "        print \"Correct dev_label -> %s\" % (dev_labels)\n",
    "        print \"dev_data below:\"\n",
    "        print \"---------------------------------------------------------------------\"\n",
    "        print\n",
    "        print dev_data\n",
    "        print\n",
    "    '''\n",
    "\n",
    "    ### STUDENT END ###\n",
    "fs2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
