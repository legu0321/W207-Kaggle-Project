{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and reshape Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "os.chdir('C:\\\\Users\\\\lgu\\\\Downloads\\\\pizza_request_dataset.tar\\\\pizza_request_dataset\\\\pizza_request_dataset' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['giver_username_if_known' 'in_test_set'\n",
      " 'number_of_downvotes_of_request_at_retrieval'\n",
      " 'number_of_upvotes_of_request_at_retrieval' 'post_was_edited' 'request_id'\n",
      " 'request_number_of_comments_at_retrieval' 'request_text'\n",
      " 'request_text_edit_aware' 'request_title'\n",
      " 'requester_account_age_in_days_at_request'\n",
      " 'requester_account_age_in_days_at_retrieval'\n",
      " 'requester_days_since_first_post_on_raop_at_request'\n",
      " 'requester_days_since_first_post_on_raop_at_retrieval'\n",
      " 'requester_number_of_comments_at_request'\n",
      " 'requester_number_of_comments_at_retrieval'\n",
      " 'requester_number_of_comments_in_raop_at_request'\n",
      " 'requester_number_of_comments_in_raop_at_retrieval'\n",
      " 'requester_number_of_posts_at_request'\n",
      " 'requester_number_of_posts_at_retrieval'\n",
      " 'requester_number_of_posts_on_raop_at_request'\n",
      " 'requester_number_of_posts_on_raop_at_retrieval'\n",
      " 'requester_number_of_subreddits_at_request' 'requester_received_pizza'\n",
      " 'requester_subreddits_at_request'\n",
      " 'requester_upvotes_minus_downvotes_at_request'\n",
      " 'requester_upvotes_minus_downvotes_at_retrieval'\n",
      " 'requester_upvotes_plus_downvotes_at_request'\n",
      " 'requester_upvotes_plus_downvotes_at_retrieval' 'requester_user_flair'\n",
      " 'requester_username' 'unix_timestamp_of_request'\n",
      " 'unix_timestamp_of_request_utc']\n",
      "(5671, 33)\n"
     ]
    }
   ],
   "source": [
    "#Load the data\n",
    "\n",
    "import pandas, json\n",
    "from sklearn.feature_extraction.text import *\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "json_data = json.load(open('pizza_request_dataset.json'))\n",
    "df=pandas.io.json.json_normalize(json_data)\n",
    "print(df.columns.values)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training label shape: (3969,)\n",
      "test shape: (3969, 32)\n",
      "test label shape: (1702,)\n",
      "test shape: (1702, 32)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.random.seed(0)\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "train, dev = train_test_split(df, test_size = 0.3)\n",
    "\n",
    "train_labels=train[\"requester_received_pizza\"]\n",
    "train_data = train\n",
    "del train_data[\"requester_received_pizza\"]\n",
    "\n",
    "dev_labels=dev[\"requester_received_pizza\"]\n",
    "dev_data = dev\n",
    "del dev_data[\"requester_received_pizza\"]\n",
    "\n",
    "print ('training label shape:', train_labels.shape)\n",
    "print ('test shape:', train_data.shape)\n",
    "print ('test label shape:', dev_labels.shape)\n",
    "print ('test shape:', dev_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text=train_data['request_text'].as_matrix()\n",
    "train_title=train_data['request_title'].as_matrix()\n",
    "train_all = train_text+train_title\n",
    "\n",
    "dev_text=dev_data['request_text'].as_matrix()\n",
    "dev_title=dev_data['request_title'].as_matrix()\n",
    "dev_all = dev_text+dev_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Text Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1)Baseline: no reprocess, no feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.319123\n",
      "precision_score: 0.334184\n",
      "recall_score: 0.305361\n"
     ]
    }
   ],
   "source": [
    "def empty_preprocessor(s):\n",
    "    return s\n",
    "\n",
    "\n",
    "vectorizer_process = CountVectorizer(preprocessor =empty_preprocessor,analyzer='word',stop_words='english' )\n",
    "word_matrix_process= vectorizer_process.fit_transform(train_all)\n",
    "dev_matrix_process = vectorizer_process.transform(dev_all)\n",
    "\n",
    "\n",
    "model_LG = LogisticRegression(penalty ='l2',C=12)\n",
    "model_LG.fit(word_matrix_process, train_labels)\n",
    "\n",
    "\n",
    "\n",
    "print('f1_score: %f' %metrics.f1_score(dev_labels,model_LG.predict(dev_matrix_process),average='binary'))\n",
    "print('precision_score: %f' %metrics.precision_score(dev_labels,model_LG.predict(dev_matrix_process)))\n",
    "print('recall_score: %f' %metrics.recall_score(dev_labels,model_LG.predict(dev_matrix_process)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####2)Add preprocessing and L1 feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix \n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "def first_preprocessor(s):\n",
    "    #convert to lowercase\n",
    "    s=s.lower()\n",
    "    s=re.sub(\"[,.!?:;/~*]\",\" \",s)\n",
    "    #remove duplicated 0s and 1s\n",
    "    s=re.sub(\"[0-9]*\",\"\",s)\n",
    "    #remove number longer than 5 digit\n",
    "    s=re.sub(\"[0-9]{5,}\",\"\",s)\n",
    "    #remove stem end with 'ly'\n",
    "    s=re.sub(\"ly\\s\",\" \",s)\n",
    "    #remove plural form\n",
    "    s=re.sub(\"s\\s\",\" \",s)\n",
    "    s=re.sub(\"s\\Z\",\" \",s)\n",
    "    #remove _ as the end of word\n",
    "    s=re.sub(\"[_]+\",\" \",s)\n",
    "    #remove _ as start of the word\n",
    "    s=re.sub(\"\\s[_]+\",\" \",s)\n",
    "    #remove stem end with 'ness'\n",
    "    s=re.sub(\"ness\\s\",\" \",s)\n",
    "    s=re.sub(\"ing\\s\",\" \",s)\n",
    "    #remove words that are too short\n",
    "    s=re.sub(\"\\s[0-9a-z]{1,2}\\s\",\" \",s)\n",
    "    s=re.sub(\"\\s[0-9a-z]{1,2}\\Z\",\" \",s)\n",
    "\n",
    "    return s\n",
    "\n",
    "def empty_preprocessor(s):\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "def tune_para(L1,L2):\n",
    "    model_LG_L1 = LogisticRegression(penalty ='l1',C=L1)\n",
    "    model_LG_L1.fit(word_matrix_process, train_labels)\n",
    "\n",
    "    index=[]\n",
    "    for i,z in enumerate(np.sum(np.abs(model_LG_L1.coef_),axis=0) ):\n",
    "        if z!=0:\n",
    "            index.append(i)\n",
    "\n",
    "    model_LG_L2 = LogisticRegression(penalty ='l2',C=L2 )\n",
    "    model_LG_L2.fit(word_matrix_process[:,index], train_labels)\n",
    "    \n",
    "    f1_score=metrics.f1_score(dev_labels,model_LG_L2.predict(dev_matrix_process[:,index]),average='binary')\n",
    "    \n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===>>No Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When l1=560 ,l2=19 , f1 score is 0.357968\n"
     ]
    }
   ],
   "source": [
    "# train_data_array=train_data['request_text'].as_matrix()\n",
    "np.random.seed(0)\n",
    "vectorizer_process = CountVectorizer(preprocessor = empty_preprocessor,analyzer='word',stop_words='english' )\n",
    "word_matrix_process= vectorizer_process.fit_transform(train_all)\n",
    "dev_matrix_process = vectorizer_process.transform(dev_all)\n",
    "\n",
    "max=0\n",
    "l1=0\n",
    "l2=0\n",
    "for i in range(500,700,10):\n",
    "    for j in range(1,50,1):\n",
    "        acc=tune_para(i,j)\n",
    "        if acc>max:\n",
    "            max=acc\n",
    "            l1=i\n",
    "            l2=j\n",
    "#         print('When l1=%i ,l2=%i , taccuracy is %f' %(i,j,acc))\n",
    "print('When l1=%i ,l2=%i , f1 score is %f' %(l1,l2,max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===>>Add Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When l1=500 ,l2=1 , f1 score is 0.335106\n"
     ]
    }
   ],
   "source": [
    "# train_data_array=train_data['request_text'].as_matrix()\n",
    "vectorizer_process = CountVectorizer(preprocessor = first_preprocessor,analyzer='word',stop_words='english' )\n",
    "word_matrix_process= vectorizer_process.fit_transform(train_all)\n",
    "dev_matrix_process = vectorizer_process.transform(dev_all)\n",
    "\n",
    "max=0\n",
    "l1=0\n",
    "l2=0\n",
    "for i in range(500,700,10):\n",
    "    for j in range(1,50,1):\n",
    "        acc=tune_para(i,j)\n",
    "        if acc>max:\n",
    "            max=acc\n",
    "            l1=i\n",
    "            l2=j\n",
    "print('When l1=%i ,l2=%i , f1 score is %f' %(l1,l2,max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####3)NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.332553\n",
      "accuracy_score: 0.334118\n",
      "recall_score: 0.331002\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "import os\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "path = '/opt/datacourse/data/parts'\n",
    "token_dict = {}\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems\n",
    "\n",
    "vectorizer_process = CountVectorizer(analyzer='word',stop_words='english',preprocessor = empty_preprocessor,tokenizer=tokenize)\n",
    "word_matrix_process= vectorizer_process.fit_transform(train_all)\n",
    "dev_matrix_process = vectorizer_process.transform(dev_all)\n",
    "\n",
    "model_LG_L1 = LogisticRegression(penalty ='l1',C=560)#C from the above test\n",
    "model_LG_L1.fit(word_matrix_process, train_labels)\n",
    "\n",
    "index=[]\n",
    "for i,z in enumerate(np.sum(np.abs(model_LG_L1.coef_),axis=0) ):\n",
    "    if z!=0:\n",
    "        index.append(i)\n",
    "            \n",
    "model_LG = LogisticRegression(penalty ='l2',C=19)#C from the above test\n",
    "model_LG.fit(word_matrix_process[:,index], train_labels)\n",
    "\n",
    "print('f1_score: %f' %metrics.f1_score(dev_labels,model_LG.predict(dev_matrix_process[:,index]),average='binary'))\n",
    "print('accuracy_score: %f' %metrics.precision_score(dev_labels,model_LG.predict(dev_matrix_process[:,index])))\n",
    "print('recall_score: %f' %metrics.recall_score(dev_labels,model_LG.predict(dev_matrix_process[:,index])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####4)PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get a list of features based on the L1 regularization, instead of inputting all words into PCA to improve the speed\n",
    "vectorizer_process = CountVectorizer(preprocessor = empty_preprocessor,analyzer='word',stop_words='english' )\n",
    "word_matrix_process= vectorizer_process.fit_transform(train_all)\n",
    "dev_matrix_process = vectorizer_process.transform(dev_all)\n",
    "\n",
    "model_LG_L1 = LogisticRegression(penalty ='l1',C=560) #C from the above test\n",
    "model_LG_L1.fit(word_matrix_process, train_labels)\n",
    "\n",
    "index=[]\n",
    "for i,z in enumerate(np.sum(np.abs(model_LG_L1.coef_),axis=0) ):\n",
    "    if z!=0:\n",
    "        index.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the first 1000 element, 0.960639 of the total variance in the training data is explained \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1589cba8>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEACAYAAACpoOGTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe7b1a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "i=1000\n",
    "pca_mod = PCA(n_components = i)\n",
    "word_matrix_process_pca=pca_mod.fit_transform(word_matrix_process.toarray()[:,index])\n",
    "print('For the first %i element, %f of the total variance in the training data is explained ' %(i,sum(pca_mod.explained_variance_ratio_)) )\n",
    "plt.plot(pca_mod.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.335052\n",
      "recall_score: 0.303030\n",
      "precision_score: 0.374640\n"
     ]
    }
   ],
   "source": [
    "dev_matrix_process_pca=pca_mod.transform(dev_matrix_process.toarray()[:,index])\n",
    "\n",
    "model_LG_L2 = LogisticRegression(penalty ='l2',C=19 )#C from the above test\n",
    "model_LG_L2.fit(word_matrix_process_pca, train_labels)\n",
    "\n",
    "print('f1_score: %f' %metrics.f1_score(dev_labels,model_LG_L2.predict(dev_matrix_process_pca),average='binary'))\n",
    "print('recall_score: %f' %metrics.recall_score(dev_labels,model_LG_L2.predict(dev_matrix_process_pca)))\n",
    "print('precision_score: %f' %metrics.precision_score(dev_labels,model_LG_L2.predict(dev_matrix_process_pca)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
